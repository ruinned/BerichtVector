\chapter{Beschreibung}
%
\section*{Erste Woche}
%
Am ersten Tag meiner Tätigkeit bei Vector bekam ich die Gelegenheit die Firma und ihre unterschiedlichen Abteilungen näher kennen zu lernen. Es war erforderlich, an einer ausführlichen Präsentation über die Firma und die unterschiedlichen Abteilungen teilzunehmen. Dabei konnte ich ebenfalls Mitarbeiter kennen lernen, die genauso wie ich, an diesem Tag mit ihrer Arbeitstätigkeit bei Vector angefangen haben.

Abbildung \ref{fig:Zeichnung1} zeigt die hierarchische Struktur der einzelnen Unternehmensabbteilungen. Ich durfte während meiner Paktikumszeit in der PES-Abteilung tätig sein.
%
\begin{figure}[htp]
\centering
%\def\svgwidth{scale=0.4}
%\input{./Bilder/Zeichnung1.pdf_tex}
\includegraphics[scale=1]{./Bilder/Zeichnung1.pdf}
\caption{Übersicht der Abteilungen bei der Vector Informatik GmbH}
\label{fig:Zeichnung1}
\end{figure}

Während des Vortrags wurden uns u.a. zahlreiche Einblicke in Themen wie vorhandene Software-Packete, Software-Sicherheit und den richtigen Umgang mit den von Vector zur Verfügung gestellten Programmen gegeben. 

Mein interner Betreuer, Markus Schwarz, stellte mir anschließend die PES Abteilung vor und begleitete mich an meinen Arbeitsplatz.

In den folgenden Tagen galt meine Arbeit der Einarbeitung und Verwendung mancher Software Tools, die von jedem Vector-Mitarbeiter zu verwenden sind. Unter anderem wird dabei eine eigene Umgebung verwendet, um die Arbeitsstunden zu dokumentieren. 

In Abbildung \ref{fig:Tortoisegit} wird ein Ausschnitt von TortoiseSVN-Versionskontroll-Software, die die Vector-Mitarbeiter verwenden, um bei jedem Software-Projekt eine geeinete Versionsverwaltung zu gewährleisten. An einer entsprechenden Schulung durfte ich während der ersten Woche ebenfalls teilnehmen.
%
\begin{figure}[htp]
\centering
\includegraphics[scale=0.6]{./Bilder/TortoiseSVN.pdf}
\caption{TortoiseSVN wird in Vector zur Versionsverwaltung eingesetzt. Entsprechende Schulungen werden ebenfalls angeboten}
\label{fig:Tortoisegit}
\end{figure}
%
\section{Erste Aufgabenstellung}
%
Innerhalb der ersten Woche wurde mir die 1. Aufgabe meiner Arbeitstätigkeit bei Vector vorgestellt. Dabei handelt es sich um den MISRA-C-Programmierstandard, über den ich mich ausführlich informieren musste. Deshalb wird im Folgenden eine Einleitung in das Thema gegeben.
%Eine genaue Rechnerche über die oben erwähnten Standards war notwendig, um nicht nur einen Einblick in das Thema zu gewinnen sondern auch die technischen Zusammenhänge zu verstehen. Deswegen wird im folgenden eine kurze Zusammenfassung über Themen gegeben, die bei der Einführung des MISRA-Standards eine wichtige Rolle gespielt haben.
%
\paragraph*{\uppercase{MISRA-C-Standard und Gründe für seine Einführung}}\label{MISRAC}
%
Die Programmiersprache C wurde im Jahr 1972 von Dennis Ritchie und Brian W. Kernighan entwickelt~\cite{CLang}. 

Im Bereich eingebetteter Systeme bietet C den Programmierern vor allem viele Möglichkeiten direkt auf die Speicherbereiche der Hardware zuzugreifen. Dadurch entsteht u.a. die Gefahr, bewusst oder unbewusst viele systemeingene Speicheradressen zu manipulieren und zu einem ungewünschten Systemverhalten zu führen. Weitere kritische Aspekte von C als Programmiersprache können in~\cite{MasterThMISRA} nachgelesen werden.

Der sogenannte MISRA-C-Standard hilft beispielsweise dabei, den bekannten Nachteilen der Programmiersprache entgegenzuwirken.

MISRA-C hat seinen Ursprung in der Automobilindustrie und wurde durch die britische \glqq The Motor Industry Sofrware Reliability Association\grqq\ eingeführt. Die erste Version wurde in 1998 mit dem Ziel veröffentlich, eine positive Auswirkung auf die Verwendung eingebetteter Software innerhalb der britischen Automobilindustrie zu haben. Seitdem ist der MISRA-Standard nicht nur im Automobilsektor eingesetzt und bekannt, sondern auch in Bereichen wie Raumfahrtindustrie oder Medizintechnik~\cite{MISRA2004}.

Eine Vielzahl an Regeln sind dabei veröffentlicht worden, um robusteren und zuverlässigeren Embedded C-Code zu produzieren. Außerdem wird damit erreicht, dass die erstellten Software-Produkte wiederverwendbar und portabler sind. 

Der zahlreiche Einsatz über die Jahre der MISRA-C-2004-Version hat vielfältige Ergänzungen und Verbesserungen als Folge gehabt. Die Regeln sind jetzt bei MISRA-C-2012 so definiert und beschrieben, dass beispielsweise die Begründungen für ihre Nutzung umfangreicher wurden~\cite{MISRA2012}. 
%
\paragraph*{\uppercase{MISRA-C-Standard in der Vector Informatik GmbH}}\label{MISRAC}
%
Zur Verifikation der MISRA-C-Kodierungsregeln wird, wie in Abbildung \ref{fig:MISRA} zu sehen, zusätzlich von Vector ein Dokument verwendet (Gemeinsames Subset der MISRA-C-Guidelines), in dem der HIS-Arbeitskreis-Softwaretest im Jahr 2006 für die MISRA-Guidelines Version 2004 eine gemeinsame Untermenge der anwendbaren Regeln festgelegt hat~\cite{HIS_Standard}. Die in diesem Dokument erwähnten Vorschriften bezüglich der MISRA-Regeln müssen bei der Herstellung und Lieferung eingebetteter Software eingehalten werden.
 
Um dies zu gewährleitsten, richtet sich Vector bei der Erstellung eingebetteter Software nach einer festgelegten Anleitung zum korrekten Programmierstil und vorgegebenen Code-Template-Files, bei denen die oben genannten Anforderungen erfüllt sind. Da diese Templates erweitert werden, ist eine Überprüfung der MISRA-Kodierungsregeln trotzdem durchzuführen. In einer sogenannte Compliance-Matrix wird festgelegt, auf welcher Art und Weise die einzelnen, relevanten MISRA-Regeln geprüft werden sollten. Hierbei kommen verschiedene statische Analysetools oder die jeweiligen Compiler in Frage. Ist die Einhaltung einer einzelnen Regel nicht komplett durch ein solches Tool automatisiert überprüfbar, dann ist man auf eine manuelle Überprüfung angewiesen~\cite{MISRA2012}.

Vector richtet sich momentan bei der Erstellung eingebetteter Software noch nicht nach der aktuellen MISRA-C-2012-Version~\cite{MISRACodeMetric}. 

Der Hauptgrund liegt darin, dass bei diesem neuen Standard viele Änderungen bei der Definition, Struktur und Aufbau der Regeln aufgetreten sind. Das bedeutet, dass sich ein Umstieg von der letzten MISRA-C-2004-Version auf die aktuelle Version nicht durchführen lässt, ohne davor einen entsprechenden Aufwand zu investieren.
%
\begin{figure}[!htp]
\centering
\includegraphics[scale=0.1]{./Bilder/MISRAoverall.png}
\caption{Struktur der bei Vector durchgeführten statischen Codeanalysen. Entnommen aus~\cite{MISRACodeMetric}.}
\label{fig:MISRA}
\end{figure}
%

Die OEMs fragen seit der Einführung von MISRA-C-2012 nach, dass die in ihren Produkten eingesetzten Embedded-Software mit dieser Version des Standards konform geht.
Vector und somit die Abteilung PES sind aus den genannten Gründen darauf angewiesen, in naher Zukunft einen Umstieg in die neue Version zu ermöglichen. 
%
\begin{Aufgabenstellung}
besteht darin, sich erstens mit den Konzepten des MISRA-C Kodierungsstandards vertraut zu machen. Anschließend sollten mögliche Rückschlüsse gezogen werden, wie umfangreich ein Umstieg von dem aktuell in der Firma geprüften Kodierungsstandard MISRA-C-2004 in den neuen Standard MISRA-C-2012 ist.
\end{Aufgabenstellung}
%
Eine detaillierte Analyse vor allem über die Kompatibilität zwischen den beiden Versionen (2004 und 2012) wird innerhalb der kommenden Wochen durchgeführt. Die Ergebnisse dieser ersten Vorarbeiten können als Grundlage weiterer Untersuchungen dienen.
%
\clearpage
\section*{Zweite Woche}
%
\section{Durchführung der ersten Aufgabenstellung}
%
Eine genaue Rechnerche über die oben erwähnten Standards war notwendig, um nicht nur einen Einblick in das Thema zu gewinnen sondern auch die technischen Zusammenhänge zu verstehen.
%
\paragraph*{\uppercase{MISRA-C-2012}}
%
Im Gegensatz zu den ersten MISRA-Versionen fordert MISRA C:2012, dass programmiertes C Code mit dem Standard \textsc{C99} \footnote{ISO Standard for the C language ISO/IEC 9899:1999~\cite{MISRA2012}} konform geht. Außerdem sind einige neue Regeln hinzugekommen, die sich hauptsächlich auf \textsc{C99} beziehen, einige wenige wurden umformuliert oder sogar entfernt~\cite{WarMISRAC}.

Bei den ersten MISRA-Versionen sind die Regeln in zwei Kategorien eingeteilt: 
notwendige (required) und empfohlene (advisory) Regel. Die ersten sind erforderliche Anforderungen an dem Programmierer. Die empfohlenen Regeln können eingehalten werden, dies ist aber nicht unbedingt notwendig.

Die einzelnen Regeln bestehen jetzt bei MISRA-C-2012 aus mehreren Teilen:

\begin{itemize}
\item Erweiterte Erläuterungen (Amplification): \\
Eine umfangreichere Beschreibeung der betrachteten Richtlinie.
\item Begründung (Rationale): \\
Erläuterung, warum die Regel benötigt wird.
\item Ausnahmen (Exceptions): \\
Beschreibung der Fälle, bei denen die betrachtete Regel nicht gilt.
\item Beispiele (Examples): \\
Beispiele, wie man die Regel anwenden kann.
\end{itemize}

\textsc{MISRA-C-2012} hat somit eine zusätzliche Kategorie eingeführt, nämlich die zwingend erforderliche Regel (mandatory). Unter keinen Umständen dürfen solche Regel verletzt werden.

Dem Begriff der Durchsetzbarkeit einer Regel wurde besondendere Aufmerksamkeit geschenkt. Die Durchsetzbarkeit besagt, wie gut sich eine Regel mithilfe einer statischen Analyse prüfen lässt. Letzteres ist von hoher Bedeutung, denn die automatische Prüfung von Regeln spart viel Zeit, wirkt sofort, ist zuverlässig, wiederholbar und konsistent~\cite{WarMISRAC}. Außerdem ist die Durchsetzbarkeit ein Maß dafür, wie abhängig ein bestimmmtes Entwicklungsprozess von der manuellen Codeanalyse ist.

Die Maßnahmen, die diesbezüglich bei der neuen MISRA-Version getroffen wurden, sind im Folgenden erläutert\footnote{Siehe dazu~\cite{MISRA2012}, Unterkapitel 6.6}:

\begin{itemize}
\item Es besteht nun ein Unterschied zwischen Regeln und Anordnungen (Directives). Regeln lassen sich direkt durch eine Analyse des Quellcodes durchsetzen. Anordnungen sind im Gegensatz dazu nicht präzise definiert, so dass ihre Einhaltung  eine genauere Untersuchung u.a. der Funktionsanforderungen benötigt.
\item Eine Regel kann innerhalb einer \textit{einzelnen Übersetzungseinheit} (Single Translation Unit) oder eines \textit{Systems} (System) analysiert werden. Diese beiden Begriffe geben den nötigen Aufwand einer Analyse wieder, um eine Regel zu überprüfen.
\end{itemize}

Abbildung \ref{fig:MISRA2004} gibt die wichtigsten Eigenschaften und Unterschiede zwischen den relevanten MISRA-Versionen wieder.
%
\begin{figure}[!htp]
\centering
\includegraphics[scale=0.7]{./Bilder/MISRA2004.pdf}
\caption{Vergleich zwischen den aktuellen MISRA-C-Versionen. In Anlehnung an~\cite{WarMISRAC}}
\label{fig:MISRA2004}
\end{figure}
%
\clearpage
\section*{Dritte Woche}\label{sec:DritteWoche}
%

%
Um den Nachweis liefern zu können, wie konform ein spezifisches Software-Projekt mit dem gesamten MISRA-C-Regelwerk geht, wird in der Regel ein ausgewähltes statisches Analysewerkzeug eingesetzt. 
%
\paragraph*{Verwendetes statisches Analysewerkzeug QA-C}\label{QAC7Einf}
%
Bei Vector wird zurzeit das Programm QA-C der Firma QA-Systems verwendet, um die statischen Code-Analysen bei ihren Software-Produkten durchzuführen~\cite{MISRACodeMetric}. Das genannte Tool ist eine kommerzielle Software zur automatisierten Überprüfung eines fetgelegten und firmenspezifischen Programmierstandards~\cite{QAC_Iseite}.

QA-C bietet die Möglichkeit eine statische Code-Analyse in 3 Phasen durchzuführen. In der 1. Phase der Analyse wird der Quellcode auf Konformität mit definierten Standards wie beispielsweise \textsc{C99} untersucht. Die drauf folgende Analyse (secondary analysis) ist ein optionale Erweiterung, bei der sich in der Regel industrie-, firmeneigene oder standardspezifische Tests durchführen lassen (MISRA-C-2004 bzw. MISRA-C-2012). In der dritten Phase wird die so genannte cross-module-Analyse durchgeführt, welche die aus dem Source Code extrahierten \textit{translation units} untersucht. Für eine genaue Beschreibung der QA-C-Funktionaliäten sei auf~\cite{QAC70WinUserGuide} verwiesen. 

Abbildung \ref{fig:QACfunc} zeigt einen Überblick über die funktionalen Beziehungen der Analyse-Software und die unterschiedlichen Ergebnisse einer beliebigen Beispielanwendung.

%
\begin{figure}[!htp]
\centering
\includegraphics[scale=1.2]{./Bilder/QAC_functions.pdf}
\caption{Funktionale Beziehungen bei der Verwendung vom QA-C-Analysetool. In Anlehnung an~\cite{QAC70WinUserGuide}.}
\label{fig:QACfunc}
\end{figure}
%

Dabei kann man erkennen, dass beim Teil \textit{Configuration} bestimmte Files notwendig sind, damit ein QA-C-Projekt initialisiert und überhaupt die Analyse stattfinden kann. Diese Einstellungsdateien werden als \textit{personalities} bezeichnet und im Folgenden näher beschrieben: 

\begin{itemize}
\item Compiler Personality ($*.p\_c$): \\
definiert die Einstellungen für den verwendeten Compiler. 
\item Analysis Personality ($*.p\_a$): \\
definiert die Analyse-Einstellungen, die projektabhängig sind wie die Include-Pfade der zu analysierenden Files.  
\item Message Personality ($*.p\_s$): \\
Einstellungen bezüglich der für die Untersuchung relevanten QA-C-Nachrichten.
\end{itemize}

Die Struktur bzw. der Aufbau der obigen Dateien wird vom Hersteller (QA-Systems) vorgegeben. Man ist deswegen zur korrekten Anwendung auf die Dokumentation der Software angewiesen. 

Ich durfte eigenständig eine statische Analyse einer einzelnen BSW-Komponente (Single Component) mit der betrachteten QA-C-Software durchführen und dabei die oben eingeführten Einstellungsdateien verwenden bzw. eingeben. Die Analyse erfolgte mithilfe der Version QA-C 7.0, für die die Abteilung über Lizenzen verfügt. Die Analysen, die mit QA-C durchgeführt werden können, beschränken sich nicht auf Kodierungsregeln wie beispielsweise die MISRA-C-Regeln. Dabei lassen sich auch funktionale und technische Fehler, potentielle Bugs sowie auch qualitative Schwachstellen im Code~\cite{QAC70WinUserGuide} erkennen. 

Die entsprechenden Ergebnisse dieser einführenden Analyse sind in \figref{fig:QAC7Single1} bzw. \figref{fig:QAC7Single} dargestellt. Wenn gemäß der vorgenommenen Einstellungen keine Findings auftreten, gehen die analysierten Files mit den vorgegebenen Kodierungsstandards komform.
%
\begin{figure}[!htp]
\centering
\includegraphics[scale=0.7]{./Bilder/QAC7Single1.pdf}
\caption{Analyse einer ersten BSW-Komponente mit QA-C7.}
\label{fig:QAC7Single1}
\end{figure}
%
\begin{figure}[!htp]
\centering
\includegraphics[scale=0.45]{./Bilder/QAC7Single.pdf}
\caption{Ergebnisse der Analyse vom betrachteten Source Code.}
\label{fig:QAC7Single}
\end{figure}
%
\clearpage
Um die Analyse des Projekts zu starten, wurden die folgenden Listings erstellt: 
%
\begin{lstlisting}[basicstyle=\ttfamily\scriptsize, caption = {Compiler personality file QA-C.p\_c}, label={lst:QAC_p_c}]
-i "C:\Program Files (x86)\Microsoft Visual Studio 10.0\VC\Include" 
-i "C:\Program Files (x86)\Microsoft SDKs\Windows\v7.0A\Include" 
-q "C:\Program Files (x86)\Microsoft Visual Studio 10.0\VC\Include" 
-q "C:\Program Files (x86)\Microsoft SDKs\Windows\v7.0A\Include" 
-it "ptrdiff_t=int"
-it "wchar_t=unsigned short"
-d "__alignof(type)=1"
-d "__based(type)="
-d "__cdecl="
-d "__COUNTER__=1"
-d "__declspec(arg)="
-d "__declspec=_ignore_paren"
-d "__event="
-d "__far="
-d "__fastcall="
-d "__forceinline=inline"
-d "__FUNCDNAME__=__FUNCTION__"
-d "__FUNCSIG__=__FUNCTION__"
...
\end{lstlisting}

\begin{lstlisting}[basicstyle=\ttfamily\scriptsize, caption = {Analysis personality file QA-C.p\_s}, label={lst:QAC_p_s}]
-rem "ShellExe=C:\Program Files (x86)\PRQA\QAC-7.0\m2cm\bin\qacsa_m2cm.exe"
-rem "EnablePostAnalysis=1"
-rem "ShellParams=%Q %F -forget cmaf"
-up "d:\uti\CDK\Tools\QAC\m2cm\messages\" 
-usr .m2cm
-l+
-format "%?u==0%(%q%:%?F%(%F%)%)(%l,%c) : %?u==0%(%?h%(Err%:Msg%)%:-->%)(%g:%N) %R(%u,  )%t MisraId %v"
-max 0
-m+
-st+
-hdr-
-summary-
-references+
-onelineonly-  
-hiddenwarnings-

-o 9
-o 40
-o 41
-o 42
-o 97
-o 159
...
\end{lstlisting}

\begin{lstlisting}[basicstyle=\ttfamily\scriptsize, caption = {Message personality file QA-C.p\_a}, label={lst:QAC_p_a}]
-il 0
-i "D:\usr\Task_01\QAC_Eval\SimpleComponent\Code\Relevant"                    
-i "D:\usr\Task_01\QAC_Eval\SimpleComponent\Code\Includes"                    
-q "D:\usr\Task_01\QAC_Eval\SimpleComponent\Code\Includes"         
-d "__MSVC_RUNTIME_CHECKS"
-d "_CHAR_UNSIGNED"
-d "_CONSOLE"
-d "_CPPRTTI"
-d "_DEBUG"
-d "_DLL"
-d "_MT"
-d "_UNICODE"
-d "CDK_CHECK_MISRA"
-d "UNICODE"
-d "VECTOR_DEBUG"
-sty exdented
-tab 2
-en ASC
-maxerr 0
...
\end{lstlisting}

Mithilfe dieser Dateien fiel es mir einfacher zu verstehen, wie die genannten Einstellungen über die \textit{personality files} durchzuführen sind. In \lstref{lst:QAC_p_c} lässt sich beispielweise erkennen, wie bei den QA-C-Compiler-Optionen über den Platzhalter $-i$ die Suchpfade für den beim analysierten Projekt verwendeten Compiler vorgegeben werden. Analog lassen sich projektabhängige Include-Pfade am Anfang der \textit{personality file} QA-C.p\_a (siehe \lstref{lst:QAC_p_a}) angeben.

Im Gegensatz zur QA-C vorgestellten Version 7.0 werden von der 9.0 Version beide relevanten Versionen des MISRA-Standards (2004 und 2012) unterstützt. Eine genaue Beschreibung dazu wird im folgenden Kapitel gegeben.
%
\paragraph*{Lösungsansatz zum Vergleich der relevanten MISRA-Versionen}
%
Das Ziel, welches man beim Lösen dieser Aufgabe verfolgt, ist eine Schlussfolgerung daraus zu ziehen, ob ein Umstieg auf den aktuellen MISRA 2012-Standard mit vertretbarem Aufwand möglich ist. Beim genannten Umstieg geht es vor allem um die Frage, ob die Struktur der Software-Produkte, die bisher bei Vector erstellt wurden, beibehalten werden kann oder diese wegen neu eingeführter bzw. geänderter MISRA-Regeln anzupassen ist. 

Als Beurteilungskriterium könnten die Ergebnisse eines Vergleichs zwischen den betrachteten MISRA C- bzw. QA-C-Versionen dienen. Würde man dabei feststellen, dass in den neuen Versionen keine großen Änderungen in der Definition oder Unterstützung der Regeln vorkommen, dann wäre der Umstieg unproblematisch möglich. Sind im Gegenteil dazu viele MISRA-Regeln bzw. viele der von QA-C geprüften Regeln neu hinzugekommen, gelöscht oder umgestrukturiert worden, dann würde der dabei entstehende Aufwand ansteigen.

Um eine erste Analyse durchzuführen, sollten erstens die Unterschiede der beiden betrachteten MISRA Standards genauer untersucht und gegenüber gestellt werden. Zweitens  sind die QA-C Versionen 7.0 und (die aktuelle) 9.0 in Bezug auf unterstützte Regeln und Toolnutzung miteinander zu vergleichen. Der Zweiter Punkt ist wichtiger im Bezug auf den oben genannten Umstieg zwischen den MISRA-Versionen, wie in den folgenden Kapitel erläurtert wird.

%Wie schon oben einführend erwähnt verfügt die PES-Abteilung über eine Lizenz der QA-C 7.0-Version, mit deren Hilfe die Konformität von eingebetteter Software mit dem MISRA-C:2004-Standard geprüft wird. 
\newpage
%
\section*{Vierte Woche}\label{sec:VierteWoche}
%
Im Gegensatz zu den von QA-C verwendeten Richtlinien zur Prüfung von MISRA-Regeln braucht man kein direkter Vergleich der MISRA-Versionen durchzuführen. Ein entsprechender Ansatz wurde bereits von der britischen \glqq The Motor Industry Sofrware Reliability Association\grqq~veröffentlicht~\cite{Addendum1}. Eine Registrierung auf der Internetseite der MISRA-Institution ist erforderlich gewesen, um Zugang zum Dokument zu erlangen.

In \figvref{fig:Addendum1} ist ein kleiner Abschnitt des genannten Dokuments zu sehen, wo die Gegenüberstellungen der beiden betrachteten MISRA-Standards gezeigt sind. 

%
\begin{figure}[!htp]
\centering
\includegraphics[scale=0.45]{./Bilder/Addendum1.pdf}
\caption{Rule mapping MISRA C:2004 $\rightarrow$ MISRA C:2012. In der vorliegenden Abbildung werden die relevanten Änderungen und Zusammenhänge zwischen den alten und den neuen MISRA-C-Regeln. Entnommen aus ~\cite{Addendum1}.}
\label{fig:Addendum1}
\end{figure}
%
%%
%\begin{figure}[htp]
%\centering
%\includegraphics[scale=0.75]{./Bilder/Addendum2.pdf}
%\caption{Rule mapping MISRA C:2012 $\rightarrow$ MISRA C:2004. Entnommen aus ~\cite{Addendum1}}
%\label{fig:Addendum2}
%\end{figure}
%%
\newpage
In \tabvref{tab:TabMisra1} bzw. \tabvref{tab:TabMisra2} werden die Ergebnisse einer ersten groben Analyse des in Abbildung \ref{fig:Addendum1} gezeigten Dokuments angegeben. Dabei ist zu erkennen, dass sowohl das Mapping \linebreak MISRA-C-2004 $\rightarrow$ MISRA-C-2012 als auch MISRA-C-2012 $\rightarrow$ MISRA-C-2004 wichtige Hinweise auf Veränderungen der Regeln liefern können. Die Bewertungskriterien sind so gewählt, dass diese eine gemeinsame Eigenschaft der neuen bzw. alten Regeln wiederspiegeln. 
%
\begin{longtable}{|l|l|}
\hline
\textbf{Eigenschaft der Regel} & \textbf{Anzahl an betroffenen Regeln} \\
\endhead
\hline
Gelöscht & 9 \\
\hline
<group prefix>-Nummer gleich geblieben & 38\\
\hline
<group prefix>-Nummer geändert & 95\\
\hline
Regel wurde in einzelnen Regeln unterteilt & 15 \\
\hline
Regel wurde in Anordnung (directive) &\\umgewandelt & 19 \\
\hline
\caption{Relevante Zusammenhänge aus Rule-Mapping MISRA-C-2004 $\rightarrow$ MISRA-C-2012.}
\label{tab:TabMisra1}
\end{longtable}
%
\begin{longtable}{|l|l|}
\hline
\textbf{Eigenschaft der Regel} & \textbf{Anzahl an betroffenen Regeln} \\
\endhead
\hline
neu eingeführt & 37\\
\hline
Regel fasst mehrere alte Regeln zusammen & 19 \\
\hline
\caption{Relevante Zusammenhänge aus Rule mapping MISRA-C-2012 $\rightarrow$ MISRA-C-2004. Das Ziel der erstellten Tabellen ist, wichtige Eingenschaften bei den durchgeführten Änderungen zwischen den betrachteten MIRSA-C-Versionen zu erkennen. Diese beiden Analysen wurde händisch durchgeführt.}
\label{tab:TabMisra2}
\end{longtable}
%

Eine weitere Untersuchung über die Unterschiede zwischen den MISRA-Versionen war mithilfe des genannten Addendum-Dokuments nicht notwendig. 

Vielmehr sollte man sich auf die im Laufe der Zeit durchgeführten Änderungen zwischen QA-C-Versionen konzentrieren, da über dieses Tool die MISRA-C-Regeln bei den Projekten in Vector geprüft werden. 

Ziel ist es somit, einen Weg zu finden, um bestimmte Muster festzulegen, die die relevanten Änderungen zwischen den Versionen 7.0 bis 9.0 möglichst gut wiedergeben.

Werden viele Änderungen bei der Toolnutzung und der in QA-C unterstützten MISRA-Prüfung festgestellt, dann kann sich der gewünschte automatisierte Umstieg als umständlich erweisen.

Bei der Analyse werden 6 relevante \textit{release notes} ausgewählt und einer ausführlichen Analyse unterzogen. Diese Dokumente beschreiben sehr gut den erwähnten Änderungsverlauf.

Die in \figvref{fig:QAC7_9Zusam} gezeigte Excel-Tabelle zeigt das Ergebnis der durchgeführten Untersuchung.
%
\begin{landscape}
\begin{figure}[!htp]
\centering
\includegraphics[scale=0.55]{./Bilder/QAC7_9Zusam.pdf}
\caption{Diese Tabelle beschreibt die erste Analyse über die Änderungen bei den vom QA-C-Analysetool geprüften Regeln, welche sich auf die MISRA-Standards beziehen.}
\label{fig:QAC7_9Zusam}
\end{figure}
\end{landscape}
%

Dabei ist auf der linken Seite des Bilds zu erkennen, dass eine Vielzahl von QA-C zugehörigen Regeln aufgezeichnet sind. Insgesamt konnte man 6150 QA-C-Nachrichten und deren entsprechende Eigenschaften zusammenfassen.

Folgende sind die Bewertungskriterien:
%
\begin{itemize}
\item \textbf{N:} New functionality has been introduced.
\item \textbf{F:} A fix of a bug or problem feature. 
\item \textbf{C:} A significant change has been implemented to existing behaviour.
\item \textbf{G/L/GL:} Messages realocated to a different message group or level.
\end{itemize}
%

In der V-Spalte der gezeigten Tabelle wird in Abhängigkeit der  modifizierten Versionen angegeben, ob die Eigenschaften der QA-C-Regel im Bezug auf die 7.0 Version gleich geblieben sind, sich geändert haben oder vielmehr neu hinzu gekommen sind. Letzteres kann man sich am Beispiel der QA-C Nachricht 4303 dadurch klar machen, dass diese Nachricht erst in der Version 8.1 eingeführt worden ist. Ab dann hat sie bis einschließlich der Version 9.0 keine Änderung erfahren. Im Gegensatz dazu gibt es neben der Nachricht 4242 eine Vielzahl von QA-C-Nachrichten, die in der Version 8.1 neu eingeführt wurden und in den weiteren \textit{release notes} Änderungen (z.B. gelöscht) erfahren haben. 

Letztere Zusammenhänge sind bei der Bewertung, inwiefern sich der erwähnte automatisierte Umstieg bei der MISRA-Prüfung ermöglichen lässt, von hoher Bedeutung. Man kann nämlich ausgehend von der Anzahl an veränderten bzw. neuen Nachrichten einschätzen, wie hoch der dabei erforderliche Aufwand ist.

\begin{longtable}{|l|l|}
\hline
\textbf{Eigenschaft der Regel} & \textbf{Anzahl an betroffenen Regeln} \\
\endhead
\hline
Gelöscht & 14 \\
\hline
neu eingeführt & 390\\
\hline
geändert(einschließlich C/F/G/L/GL) & 356\\
\hline
\caption{Diese Tabelle beschreibt die Zusammenfassung der gefundenen Unterschiede bzw. Änderungen bei den vom QA-C-Analysetool geprüften Regeln, welche sich auf die MISRA-Standards beziehen.}
\label{tab:TabQAC7_9}
\end{longtable}

\tabvref{tab:TabQAC7_9} stellt besipielhaft wichtige Bewertungskriterien dar, um eine plausible Aussage über den angestrebten automatisierten Umstieg der betrachteten MISRA-Analysen geben zu können. 

In erster Linie sind im Laufe der Versionen eine hohe Anzahl an neuen geprüften QA-C-Nachrichten eingeführt worden. Auf der anderen Seite gibt es sehr viele Nachrichten, deren Struktur geändert oder angepasst worden sind. Wird ein Entwicklungsprojekt mit der Version 9.0 des QA-C-Analysetools geprüft, dann ist mit hoher Wahrscheinlichkeit zu erwarten, dass dabei eine hohe Anzahl an Warnungen angezeigt werden. Die entsprechenden Stellen im Code, auf welche sich die Warnungen beziehen, müssten nachträglich  dementsprechend händisch einzeln angepasst\footnote{Die entsprechenden \glqq deviations\grqq~im Code müssten durch plausiblen \glqq justifications\grqq~begründet werden.} werden.
\newpage
%
\section*{Fünfte Woche}\label{sec:VierteWoche}
%
Beim letzten Teil der ersten Aufgabestellung ginge es darum eine Vielzahl von Basissoftware-Modulen sowohl mit QA-C 7.0 als auch QA-C 9.0 zu analysieren. Ziel dieser Teilaufgabe ist es, eine Voruntersuchung zur Integration von QA-C9\footnote{QA-C9 weist auf die Version 9.0 des betrachteten Analysewerkzeugs hin} in die bestehende Entwicklungsinfrastruktur durchzuführen.

Vor der Beschreibung der genannten QA-C-Analysen wird auf die Einstellungen eines QA-C9-Projekts eingegangen.
%
\paragraph*{Bestandteile und wichtige Einstellungen eines QA-C9-Projekts}
%
Erst dieses Jahr veröffentlichte QA-Systems die genannte QA-C9-Version. Aus diesem Grund konnte die Voruntersuchung nur mithilfe einer Testlizenz stattfinden.

Die Dokumentation, welche von QA-Systems zur Verfügung gestellt wird, sollte zur richtigen Verwendung des Tools genau analysiert werden. Im Vergleich zu den \textit{personality files}, die bei QA-C7 verwendet wurden, ähnliche Files in QA-C9 erstellt werden, um ein Projekt einzustellen. 

Analog zum Unterkapitel \ref{QAC7Einf} werden im Folgenden die Einstellungsfiles eines QA-C9 Projekts zusammenfassend eingeführt:

\begin{itemize}\label{it:ConfFileQA9}
\item Analysis Configuration File (ACF): \\
definiert die Analyse-Einstellungen, die projektabhängig sind wie Include-Pfade, projektabhänigie Defines, usw.
\item  Rule Configuration File (RCF): \\
Einstellungen bezüglich der für die Untersuchung relevanten QA-C-Nachrichten.
\item Compiler Compatibility Templates (CCT): \\
definiert die Einstellungen für den Compiler, der bei der Entwicklung der Source Files verwendet wird. 
\item Project Definition File (prqaproject.xml): \\
Hierbei werden u.a. die Pfade der zu analysierenden Files angegeben.
\end{itemize}

Mit der QA-C9-Version ist es möglich über die vorhandene Benutzeroberfläche (siehe \figvref{fig:QAC9_GUI}) die Einstellungen vorzunehmen oder ebenfalls dadurch, dass man die oben genannten Files entsprechend bearbeitet. Abbildung \ref{fig:QAC9_GUI} zeigt die GUI der aktuellen QA-C9-Version, die im Vergleich zur QA-C7-Version benutzerfreunlicher gestaltet ist.
%
\begin{figure}[!htp]
\centering
\includegraphics[scale=0.5]{./Bilder/QAC9_GUI.pdf}
\caption{Benutzeroberfläche der QA-C9-Software. Diese GUI ist im Vergleich zu der QA-C7-Version benutzerfreundlicher gestaltet.}
\label{fig:QAC9_GUI}
\end{figure}
%
\paragraph*{Ergebnisse einer statischen Analyse mithilfe von QA-C9}
%
Um sich mit QA-C9 vertraut zu machen, lohnt es sich, mit der Analyse für die bereits im Unterkapitel \ref{QAC7Einf} behandelte \textit{simple component} klein anzufangen.

Nachdem das QA-C9-Projekt über die GUI eingestellt wurde, war es möglich entsprechende Reports zu erstellen. Die Reports können direkt als HTML-Files ausgegeben werden und Hinweise, ob bei der Analyse Findings aufgetretten sind, sind aus bestimmten Stellen in der GUI abzulesen.

Der wesentliche Unterschied zwischen den QA-C7- und QA-C9-Versionen besteht darin, dass in der QA-C7-Version die Report-Findings bei einem bestimmten Header File sich in der gesammten Analyse ausbreiten. Dies geschieht, wenn diese Files in anderen Files eingebunden werden. Leider lassen sich die Findings eines bestimmten Files schlecht von diesen genannten Findings unterscheiden. Dies ist bei der QA-C9-Version nicht der Fall, denn dabei werden die Findings von eingebundenen Header-Files isoliert behandelt und gehen nicht in den Report anderer Files ein.

Die Ergebnisse der Analyse mit der Version 7.0 wurden zusammen mit den oben genannten Ergebnissen der Reports verglichen und sind in \figvref{fig:QACSimpleComp} mittels einer Tabelle dargestellt.

Auf der linken Seite der Abbildung sind die analysierten Files dargestellt. Die Ergebnisse sind nach den verwendeten Versionen sortiert. Eine solche Darstellung kann hilfreich sein, um beipielsweise Nachrichten aufzuzeichnen, die bei einem bestimmten analysierten File in einer Version jedoch nicht in der anderen erkannt werden. Das ist der Fall beispielsweise bei der Nachricht 841, die in allen Files bei der Version 7.0 jedoch in keiner der folgenden Versionen erkannt wird. 
%
\begin{figure}[!ht]
\centering
\includegraphics[scale=0.7]{./Bilder/QACSimpleComp.pdf}
\caption{Ergebnisse einer statischen Codeanalyse, die bezüglich einer \textit{simple component} mithilfe der QA-C7- und QA-C9-Versionen durchgeführt wurde. Auf der linken Seite der Abbildung sind die analysierten Files dargestellt. Die Ergebnisse sind nach den verwendeten Versionen sortiert.}
\label{fig:QACSimpleComp}
\end{figure}
%

Drauf aufbauend sollte ein umfangreicheres QA-C9-Projekt zur statischen Codeanalyse einer größeren Anzahl an BSW-Files eingestellt werden. In diesem Fall würde sich die Einstellung eines solchen Projekts als sehr umständlich erweisen, wenn dies händisch durchgeführt wird. Dies liegt daran, dass die Quelldateien sich normalerweise in mehreren Unterordner organisiert befinden und die jeweiligen Pfade angegeben werden müssen. Letzteres betrifft sowohl die Eingabe der Einstellungsfiles über die GUI als auch die manuelle Bearbeitung der Einstellungsfiles ACF, RCF, CCT sowie der XML-Project-Definition-Datei. 
%
\newpage
\section*{Sechste Woche}
%
Bei einer solchen großen Anzahl an zu analysierenden Files, die in der Regel sehr oft bei einem Entwicklungsprojekt vorkommen, sollte eine automatisierte Generierung von Analysereports möglich sein. Hierbei könnte die Verwendung einer Skriptsprache wie PERL oder Phyton Abhilfe schaffen. Letztere erleichtern u.a. den automatisierten Umgang mit Textdateien und Verzeichnissen.

Da bisher in der Abteilung einige Mitarbeiter bei der Programmierung mit PERL große Erfahrung gesammelt haben, entschloss ich mich diese Programmiersprache zur Bearbeitung der Konfigurationsdateien einzusetzen. Eine kostenlose IDE, mit der es möglich ist, \verb|PERL|-Skripte zu erstellen, kompilieren und Debuggen ist nicht leicht zu finden. Eine gute Alternative bietet die in Abbildung \ref{fig:EPICskr1} gezeigte EPIC-IDE \cite{EPICIDE}. Diese steht als Eclipse-Plugin kostenlos zur Verfügung und stellt nicht nur die Möglichkeit dar, \verb|PERL|-Skripte zu bearbeiten, sondern auch diese zu kompilieren und mit einem integrierten Tool zu debuggen. Außerdem ist diese sehr bekannt, wobei das Support ausreichend in Foren zu finden ist.

Bei der Installation und Inbetriebnahme dieser \verb|PERL|-IDE muss man auf bestimmte Fehlermeldungen achten, die sich meistens auf die Version des verwendeten \verb|PERL|-Kompilers beziehen. Um diese zu beheben, ist man auf Internetrecherche angewiesen.

Um die genannten Files von den unterschiedlichen Verzeichnissen in ein einzelnes Verzeichnis zu übertragen, wurde \lstref{lst:PERL_Dateiueb} erstellt.
%
\begin{figure}[!ht]
\centering
\includegraphics[scale=0.6]{./Bilder/EPIC_skr1.pdf}
\caption{Eclipse-Benutzeroberfläche bei Anwendung der \texttt{PERL}-IDE.}
\label{fig:EPICskr1}
\end{figure}

Die Übertragung der Dateien war nicht die einzige Aufgabe, die zum Erstellen des QA-C9-Projektes durchgeführt werden musste. Es war außerdem notwendig die Pfade der einzelnen zu analysierenden Dateien anzugeben. Wie weiter oben in diesem Kapitel erläutert, bedient sich QA-C9 einer XML-Konfigurationsdatei, um dabei sowohl die Pfade der zu analysierenden Dateien als auch weitere wichtige Einstellungen festzulegen.

Diese XML-Datei als Textdatei so zu bearbeiten, dass dabei die richtige Einträge hinzugefügt werden, ist sehr hilfreich, um eine automatisierte statische Codeanalyse von sehr vielen Sourcefiles durchzuführen. Dies ist das Ziel, um im Nachhinein die ganze statische Codeananalyse lediglich durch den Aufruf der richtigen Befehle über eine Kommandozeile ausführen zu können.
Dazu wird ein von QA-Systems zur Verfügung gestellte Compiler mit den richtigen Optionen aufgerufen, wobei dem Compiler auch die richtigen QA-C9-Konfigurationsdateien zur Verfügung stehen müssen. Diese Methode hat man zwar bisher in der Abteilung eingesetzt, der dabei verwendeter Compiler gehört zu der QA-C7-Version \cite{MISRACodeMetric}.

Da die Version QA-C9 einen ähnlichen Compiler (QA-CLI) zur automatischen Ansteuerung einer statischen Codeanalyse bietet, ist es hilfreich, sich die dazu nötigen Compiler-Optionen anzuschauen und auszusuchen. Eine genaue Beschreibung der dabei relevanten Compilerbefehle bezüglich der QA-C9-Version können in \cite{PRQA9}~nachgelesen werden.

Damit die erwähnten Konfigurationsfiles dem QA-CLI-Compiler zur Verfügung stehen, müssen diese erstmal mit den richtigen Informationen aufbereitet werden. Dadurch würde sich die automatisierte statische Codeanalyse über Compiler-Aufrufe bzw. über einen Batch-Skript auszuführen lassen.

Um die Aufbereitung der Einstellungsfiles habe ich ebenfalls die bei der Programmierung des ersten \verb|PERL|-Skripts erworbenen Kenntnisse genutzt. In dieser zweiten Anwendung bearbeitet ein neuer \verb|PERL|-Skript ein vorhandenes Template-File eines QA-C9-Projekts, welches nur wenige Einträge enthält. Dann werden die relevanten, zu analysierenden Files und deren Pfadenamen hinzugefügt. Das Ergebnis nach der Ausführung des in \lstref{lst:PERL_XML} angegebenen \verb|PERL|-Skripts kann im folgenden Listing betrachtet werden. Zu erwähnen ist, dass dies nur ein kleiner Ausschnitt der gesamten Einträge ist.
%
\definecolor{forestgreen}{RGB}{34,139,34}%definition fuer xml Comment style 
\begin{lstlisting}[language=XML, caption = {Project Definition File (prqaproject.xml) bezüglich der QAC-9-Version}, label={lst:QAC9_xml}]
...
 <!-- Files in project... -->
 <files>
  <!-- Explicit files... -->
  <file target="C" name="Adc.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="BswM.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="Can.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="Can_Irq.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="CanIf.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="CanNm.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="CanSM.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="CanTp.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="CanTrcv_30_GenericCan.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="CanTSyn.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="CanXcp.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="Com.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="ComM.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="Crc.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="Cry.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>  
...
\end{lstlisting}
%
Dabei ist ersichtlich, wie die Namen der zu analysierenden Files und die Pfade anzugeben sind, wo sich dieselben befinden. Dies händisch bzw. per Maus-Klick über die GUI einzutragen wäre sehr mühsam, was auf die Notwendigkeit der automatisierten Handhabung dieser Einstellungen hinweist.
%
\section{Ergebnisse der 1. Aufgabenstellung}
%
Eine erste detaillierte Analyse über die Kompatibilität zwischen den beiden MISRA Versionen (2004 bzw. 2012) wurde durchgeführt. Es wurde festgestellt, dass von der britischen \glqq The Motor Industry Sofrware Reliability Association\grqq~bereits ein Dokument veröffentlicht wurde, welches die Änderungen und Gemeinsamkeiten zwischen den genannten Versionen aufzeichnet. Dieses Dokument kann als Grundlage dienen, um handische Vergleiche zwischen den beiden Versionen durchzuführen.

Außerdem wurde eine Analyse zwischen der aktuell von Vector eingesetzten QA-C7- und der letzten QA-C9-Version des statischen Analysetools. Dabei war das Ziel die im Laufe der Zeit bezüglich der neuen Version eingeführten Änderungen festzulegen. 

In beiden Fällen wurde festgelegt, dass Regeln sowohl gelöscht als auch neu eingeführt wurden. Umganreiche Änderungen in der Struktur vieler geprüften MISRA- bzw. QA-C-Regeln sind eingeführt worden. Dies weist auf eine nicht zu vernachlässigende Wahrscheinlichkeit hin, dass bei einer statischen Codeanalyse von bestehenden Software-Komponenten mit der neuen QA-C-Version eine Vielzahl an Warnungen gemeldet werden. Der alysierte Code kann somit bezüglich der neuen MISRA-Regeln mit einem hohen Aufwand so angepasst werden, dass diese Abweichungen nicht mehr auftretten.

Anschließend wurden zwei Möglichkeiten vorgestellt, um ein Projekt mit der neuen QA-C9-Version des statischen Analysetools aufzustellen. Es wurden dabei zwei \verb|PERL|-Skripte programmiert, um einerseits zahlreiche Files von einem Verzeichnis in einen anderes zu übertragen, ohne dies händisch durchführen zu müssen. Andererseits lässt sich mit dem zweiten Skript ein XML-Templatefile (Project Definition File) bearbeiten, welches für eine automatisierte statische Codeanalyse nötig ist. Im Gegensatz dazu wird diese Art der Verarbeitung von Text-Files in der Abteilung über Batch-Skripts und andere programmiersprachen durchgeführt.
%
\newpage
\section*{Siebte Woche}
%
In der siebten Woche wurde mir die 2. Aufgabestellung vorgestellt. Dabei ginge es darum, mich umfassend mit einem Basic Test Environment (BTE) zu beschäftigen, welches in der PES Abteilung entwickelt wurde. Ich musste mich mit dem Tool vertraut machen und seine Funktionsweise verstehen, um es anschliessend um weitere Funtionalitäten zu erweitern.
%
\section{Zweite Aufgabenstellung}
% 
Wie oben erwähnt war es notwendig die wichtigsten Eigenschaften und Besonderheiten vom BTE-Tool zusammenzufassen und kennenzulernen. Anhand dieser Analyse wird es klarer, an welcher Stelle die Funktionalitäten zu ergänzen sind.
%
\subsubsection*{BTE - Basic Test Environment}
%
Das BTE ist ein in \verb|C| implementiertes Component-Unit-Test-Framework, mit dessen Hilfe man in der Abteilung hardwareunabhängige (AUTOSAR-) BSW-Komponeneten testet \cite{BTE}.

Die in Abbildung \ref{fig:BTE_func1} vorgestellte BTE-Version bietet verschiedene Testsfunktionalitäten, u.a. das Nachbilden (emulation) einer inneren ECU-Umgebung, die Ereignisprotokollierung und das Erstellen von entsprechenden Reports \cite{BTE}. 
%
\begin{figure}[!htp]
\centering
\includegraphics[scale=0.8]{./Bilder/BTE_func1.pdf}
\caption{Framework-Emulation of ECU environment on a PC. Entnommen aus \cite{BTE}.}
\label{fig:BTE_func1}
\end{figure}
%

Im Diagram wird durch die rote Box die Nachbildung der inneren ECU-Umgebung gezeigt. Diese Box besteht aus mehreren Platzhaltern, sogenannten Stubs, die Komponenten simulieren/ersetzen. Dabei ist ersichtlich, dass der Testplan sowohl die simulierten Stubs als auch die Component Under Test (CUT) steuert, damit vom Framework einen entsprechenden Log/Report ausgegeben wird. Aufgrund der stubbasierten Funktionsweise des vorgestellten Frameworks, ist es nicht nötig die gesammte Komponenten, die in einem Stuergerät vorkommen, zu betrachten. Dies ist ein großer Vorteil.

Das Klassendiagram, welches in Abbildung \ref{fig:BTELogListold} gezeigt wird, gibt einen Teil der existierenden BTE-Struktur wieder. Das Teilmodul \verb+TestHandler+ steuert den Ablauf der Testdurchführung, wobei nur über das Modul \verb+BteReport+ auf die Testreport-Datei zugegriffen wird, um diese zu bearbeiten. Die Funktionalität \verb+BteCheckX+ bezeichnet bestimmmte Komponenten der BTE, die wie das Modul \verb+BteReport+ direkt auf den VTR-Report zugreifen, um beispielsweise bestimmte Meldungen auszugeben. Die dabei verwendete Methodesaufrufe werden nicht als solche zu testende Methodensaufrufe von der BTE registriert. 
%
\begin{figure}[!htp]
\centering
\includegraphics[scale=0.75]{./Bilder/BTELogListold_cropped.pdf}
\caption{Klassendiagramm zur Ergänzung der Softwarespezifikation des erweiterten BTE-Tools. Dabei können die funktionalen Zusammenhänge zwischen den ursprunglichen Modulen erkannt werden.}
\label{fig:BTELogListold}
\end{figure}
%

Gegenüber den genannten Funktionalitäten bzw. Vorteile gibt es bei der Verwendung des BTEs folgenden Nachteil, der sich eher als eine Einschränkung äußert: Mit dem Tool lassen sich bequem Testreports auf einem lokalen Rechner ausgeben und abspeichern. Dabei werden jedoch betriebssystemabhängige Funktionen zum Umgang mit Strings benötigt, die in der Regel viele Hardwareresourcen verbrauchen. Die BTE lässt sich somit nur auf Rechnern sinnvoll einsetzen, die genug Arbeitsspeicher und Speicherplatz zur Verfügung stellen.

\begin{Aufgabenstellung}
Die Aufgabestellung basiert somit auf folgender Anforderung: Es wäre vorteilhalft, die BTE-Struktur (siehe Abbildung \ref{fig:BTELogListold}) so zu erweitern, dass das Tool ebenfalls auf einem eingebetteten System läuft. Der Grund dafür ist, dass es dadurch möglich wäre, Testreports von BSW-Komponenten unter realen Bedingungen erstellen zu können. 
\end{Aufgabenstellung}
%
\subsubsection*{Test-Hardware}
%
Eine Test-Hardware, auf der die BTE laufen soll, wurde mir zur Verfügung gestellt. Es handelte sich dabei um das STM32F4-DiscoveryBoard, auf dem der  Mikrocontroller STM32F407VG (Cortex-M4-Hardwarearchitektur) eingebaut ist. Siehe Abbildung \ref{fig:discovery}.

Um die Aufgabe zu lösen, war es notwendig das STM32F4-DiscoveryBoard in Betrieb zu nehmen und dabei eine passende Entwicklungsumgebung zu verwenden. Diese sollte dementsprechend geeignete Compiler- und Linker-Bibliotheken zur Verfügung stellen, die das Erstellen einer Applikation für den  Mikrocontroller unterstützen. 
%
\begin{figure}[!htp]
\centering
\includegraphics[scale=0.4,angle=90]{./Bilder/stm32f4_discovery.jpg}
\caption{Verwendete Test-Hardware (STM32F4), auf welcher die RT-BTE lauffähig sein soll.}
\label{fig:discovery}
\end{figure}
%

Da ich in vergangenen Projekten bereits Erfahrung bei der Programmierung des genannten Mikrocontrollers sammeln konnte, entschloss ich mich die Eclipse-IDE und das dabei zur Verfügung stehende CDT\footnote{C/C++ Development Tooling}-Plugin einzusetzen. Dieses erweitert Eclipse und bietet u.a. die Möglichkeit C/C++ Programme zu editieren, zu kompilieren und zu linken~\cite{EclipseCDT}. 

In ~\cite{EclipseSTM32Youtube} werden weitere, notwendige Tools angegeben, die die Programmierung des Mikrocontrollers ermöglichen:
%
\begin{itemize}
\item GDB Hardware Debugging: ein zusätzliches Eclipse-Plugin
\item GDB: der GNU Debugger-Programm
\item GDB-Server: stellt eine Verbindung mit GDB und dem JTAG-Interface her.
\item Toolchain: make, Compiler, Linker, GDB, Bibliotheken, usw.
\end{itemize}
%
\newpage
%
\section*{Achte Woche}\label{siebteWoche}
%
\section{Durchführung der zweiten Aufgabenstellung}\label{durchfAuf2}
%
Jedes Software-Projekt basiert auf einer grundlegenden Anforderungsanalyse. Bei der vorliegenden Aufgabe wurde ebenfalls eine Anforderungsanalyse durchgeführt, welche im folgenden vorgestellt wird.
%
\subsection*{Anforderungsanalyse}\label{Anforderungen}
%
Die Erweiterung des BTE-Tools soll folgende Anforderungen erfüllen:
%
\begin{enumerate}
\item Ursprüngliche Implementierungen der BTE-Funktionalitäten, sollen durch Erweiterungen möglichst wenig modifiziert werden.
\item Es soll auf einem Embedded-Prozessor lauffähig sein und mit vorhandenen Hardware-Ressourcen möglichst sparsam umgehen.
\item Die ursprüngliche BTE-Funktionalitäten, einen Test einer Software-Komponente auf einem lokalen Rechner durchzuführen und dabei einen passenden Report zu erstellen, sollen immer noch vorhanden sein.
\item Ein Testreport soll bei Verwendung des BTE-Frameworks auf einem eingebetteten System durch eine entsprechende Kodierung auf der RAM des betrachteten Systems abgespeichert werden können.
\item Eine Funktionalität soll vorhanden sein, um aus einer vorgegebenen Binärdatei einen Testreport erstellen zu können. Die Binärdatei stellt den RAM-Speicherbereich dar, wo sich der kodierte Testreport befindet.
\item Der aus der Binärdatei erstellte Testreport soll dieselbe Struktur eines Testreports haben, der über das BTE auf einem lokalen Arbeitsrechner erstellt wird.
\end{enumerate}
%
In Abbildung \ref{fig:BTEUseCase} wird ein Anwendungsfalldiagramm gezeigt, um die funktionalen Anforderungen an dem vorliegenden System besser zu verstehen. 

Dabei ist ersichtlich, dass lediglich der Anwendungsfall \textsf{\textbf{excecute test on embedded device}} die ursprüngliche BTE-Funktionalitäten erweitert. Dieser Anwendungsfall beschreibt somit die zu implementierenden Anpassungen und Erweiterungen. Nachdem die Implementierungen der Lösungen zu dieser Aufgabe und dadurch die oben genannten Anforderungen erfüllt werden, hat der Anwender die Möglichkeit, über das erweiterte Tool Tests sowohl auf einem lokalen Arbeitsrechner als auch auf einem eingebettenen Prozessor durchzuführen. Ein Report kann ebenfalls mithilfe des erweiterten Tools erstellt werden. Im gezeigten Anwendungsfalldiagram ist somit nicht relevant, über welchen Weg der entsprechende Testreport erzeugt wird. Dabei ist wesentlich, dass das Tool ebenfalls Reports auf einem eingebetteten System erstellen kann.
%
\begin{figure}[!htp]
\centering
\includegraphics[scale=0.9]{./Bilder/BTEUseCase.pdf}
\caption{Anwendungsfalldiagramm zur Ergänzung der Softwarespezifikation des erweiterten BTE-Tools.}
\label{fig:BTEUseCase}
\end{figure}%
%
\subsubsection*{Verwendeter Lösungsansatz}\label{Ansaetze}
%
Man muss mit den vorhandenen Hardwareressourcen des eingebetteten Systems, wo die BTE eingebunden werden soll, sparsam umgehen und dabei auch eine Methode einsetzen, bei der beispielsweise der Test-Report direkt auf dem beschränkten RAM-Speicher abgelegt wird. Dazu ist es notwendig, eine bestimmte Codierung festzulegen, wie die Daten abzuspeichern sind.

Am Ende der Testdurchführung soll der Test-Report wieder als eine XML-Datei vorliegen. Dies kann nur dann erreicht werden, wenn die entsprechenden Stellen des RAM-Speichers aus dem eingebetteten System extrahiert und anschließend analysiert werden. Dieser RAM-Bereich, welcher als eine Binärdatei vorliegt, würde sich mithilfe einer Anwendung analysieren lassen. Diese Anwendung wird in einer ausgewählten Skriptsprache programmiert und implementiert die Dekodierung der Daten, um einen Test-Report wie gefordert als eine XML-Datei zu erstellen.

Zwei Mögichkeiten können dabei betrachtet werden, um mit den knappen Softwareressourcen der Embedded Platform umzugehen:

\begin{enumerate}
\item Man bindet entsprechende einzelne Methoden ein, die speziell implementiert worden sind, um auf Hardwareressourcen-beschränkte Systeme zu laufen.
\item Durch entsprechende Präprozessor-Direktiven werden diejenigen Teile vom vorhandenen BTE-Code beim Kompiliervorgang ausgeblendet, die viele Hardware-Ressourcen benötigen.
\end{enumerate}

Die zweite Möglichkeit wird zur Lösung der Aufgabe gewählt. Dabei wird wie folgt vorgegangen:

Mit vorhandenen und zusätzlich eingeführten Präprozessor-Direktiven (\verb+#define+) wird die Möglichkeit geboten, die betroffenen BTE-Methodensaufrufe auszublenden. Ebenfalls sollten solche Methodensaufrufe ausfallen, die von der eingebetteten Hardware nicht unterstützt werden. Ein Beispiel dazu sind solche Methoden, die das lokale Abspeichern von Dateien ermöglichen wie fopen, fclose, sprintf, usw. 

\begin{description}
	\item[\textbf{\texttt{\#define USE\_PRINTF}}]: Mithilfe dieser neu eingeführten Direktive wird der 2. Anforderung Rechnung getragen. Dabei sollen bei Anwesenheit dieser Direktive alle Codeabschnitte ausgeblendet werden, bei denen Strings und deren Verarbeitung vorkommen. Diese Teile können nur dann eingesetzt werden, wenn die Hardware genug RAM zur Verfügung stellt und geeignete Methoden implementiert sind. Es wird im folgendenden Codeabschnitt des BTE-Files \verb|BteTestHandler.c| beispielshaft gezeigt, wie durch den Einsatz der genannten Präprozessor-Direktive die Zeilen 7-12 ausgeblendet werden können, um den Verbrauch von großen RAM-Speicherbereichen zu vermeiden. Ebenfalls werden in \lstref{lst:useprintf1} Codeabschnitte entfernt, die die Methode \verb|sprintf| verwenden.
%
\begin{lstlisting}[style=C_colored_smallfont, caption = {Ausschnitt aus BteTestHandler.c}, label={lst:useprintf1}]
...
typedef struct stBteTestSequence
{
  uint16 id_num;
  uint8 isOpen;
#if defined ( USE_PRINTF )
  char  description_id[50];
  char  description_name[100];
  char  description_parameter[100];
  char  description_purpose[100];
  char  description_reference[100];
  char  description_text[1000];
#endif
} tBteTestSequence;
...
\end{lstlisting}
%
\clearpage
\begin{lstlisting}[style=C_colored_smallfont, caption = {Ausschnitt aus BteCheck.c}, label={lst:useprintf1}]
...
void BteAvailableOk( char *text )
{
#if defined USE_PRINTF
  char output[kBteTextSize];
  sprintf( output, "%s is available (as expected)", text );
  BteOk( output );
#else
  BteOk( text );
#endif
}
...
\end{lstlisting}
%
\item[\textbf{\texttt{\#define USE\_INTERNAL\_LOG}}]: Mithilfe dieser neu eingeführten Direktive wird den Anforderung 1, 2, 3 und 4 Rechnung getragen. Dabei werden diejenigen Stellen vom Code eingeblendet, wo die von mir implementierten Module vorkommen. In \lstref{lst:useinternal1} wird die Funktionalität eingeschaltet, bestimmte Meldungen in den Testreport auszugeben, ohne dass diese Aufrufe in dem Report selbst vorkommen. In \lstref{lst:useinternal2} wird desweiteren die Funktionalität eingeführt, die auftretenden Testcase-Events in den RAM-Speicher abzulegen. 
%
\begin{lstlisting}[style=C_colored_smallfont, caption = {Ausschnitt aus BteCheck.c}, label={lst:useinternal1}]
...
#if defined ( USE_INTERNAL_LOG )
  BteLogList_Message(kBteMessageType_Error, BteTestCase_GetTime());
#endif
...
\end{lstlisting}
%
\begin{lstlisting}[style=C_colored_smallfont, caption = {Ausschnitt aus BteLog.c}, label={lst:useinternal2}]
...
#if defined USE_INTERNAL_LOG
    // Event entry in the internal array list
    BteLogList_AddEvent( pEvent );
#endif
...
\end{lstlisting}
%
\item[\textbf{\texttt{\#define BTE\_ENABLE\_TESTREPORT}}]: Durch das Umdefinieren dieser schon vorhandenen Direktive wird ein Ausblenden derjenigen Methodensaufrufe möglich, die mit dem Erstellen, der Bearbeitung und lokalen Abspeicherung von Dateiobjekten umgehen. Dadurch kann den Anforderungen 1, 2 und 3 Rechnung getragen werden. Siehe dazu \lstref{lst:usetestrep1} bzw. \lstref{lst:usetestrep2}. In den dabei vorkommenden Methodensaufrufe wird der Methodensaufruf \verb|fprintf| eingesetzt, der in der Regel von keinem eingebetteten System unterstützt wird, da solche Systeme die benötigten Hardwareressourcen nicht zur Verfügung stellen.

\begin{lstlisting}[style=C_colored_smallfont, caption = {Ausschnitt aus BteLog.c}, label={lst:usetestrep1}]
...
#if defined (BTE_ENABLE_TESTREPORT)
    uint8 tempText[150];
    sprintf(tempText,"%s %s",pEvent->text_name,pEvent->text_param);
    if( pEvent->type == kBteEventType_Command )
    {
      BteReport_WriteElement( "cmd", pEvent->time, tempText );
    }
    else if ( pEvent->type == kBteEventType_Error )
    {
      BteReport_WriteElement( "fail", pEvent->time, tempText );
    }
    else
    {
      BteReport_WriteElement( "", pEvent->time, tempText );
    }
    BteTraceReport_WriteElement( pEvent );
#endif
...
\end{lstlisting}	
%
\begin{lstlisting}[style=C_colored_smallfont, caption = {Ausschnitt aus BteReport.c}, label={lst:usetestrep2}]
...
void BteReport_Write( char *text )
{
#if defined ( BTE_ENABLE_TESTREPORT )
  if( pBteTestReport != 0 ) 
  {
    fprintf( pBteTestReport, "%s\n",text );
  }
#endif
}
...
\end{lstlisting}
%
\end{description}
%
\newpage
\section*{Neunte Woche}
%
Bei jeder Testdurchführung können je nach Voreinstellung die Ergebnisse der Methodensaufrufe in Form eines XML-Reports ausgegeben werden, was in Abbildung \ref{fig:ReportXML} gezeigt wird. Nach jedem dieser Methodensaufrufe besteht die Möglichkeit, die dabei übergebenen Parameter auch im Testreport auszugeben. Deshalb werden diese Parameter bei jedem Methodensaufruf vom BTE-Tool gespeichert und anschliessend im Report ausgegeben. Dadurch ist es im Report ersichtlich, dass bei einer bestimmten Konstellation von Übergabeparametern der Methodensaufruf nicht gelungen ist.  
%
\begin{figure}[!htp]
\centering
\includegraphics[scale=0.4]{./Bilder/ReportXML.pdf}
\caption{XML-Format eines VTR-Files, welches in Vector als Grundlage weiterer Testreviews verwendet wird.}
\label{fig:ReportXML}
\end{figure}
%

Bei der Verwendung des BTE-Tools auf einer beliebigen eingebetteten Hardware können bestimmte existierende Funktionalitäten nicht wie gewohnt verwendet werden, damit beispielsweise die Testcases mit einer entsprechenden ID-Nummer gestartet und gekennzeichnet werden. Diese Initialisierung muss vor jeder Testcase-Durchführung geschehen.

Die alte Methode \verb|BteTestCase_SetData( uint8 type, char *text )| soll durch eine verwandte Methode ersetzt werden, bei der lediglich die Testcase-ID-Nummer \texttt{testcaseID} bzw. kein String übergeben wird. Der User ist deswegen angewiesen, stattdessen folgende Methode aufzurufen:
%
\begin{lstlisting}[style=C_colored_smallfont, caption = {Ausschnitt aus BteTestHandler.c}, label={lst:BteTestCase_SetData_ID}]
...
void BteTestCase_SetData_ID( uint16 id_num )
{
  bteTestSequence.id_num = id_num;
}
...
\end{lstlisting}
%
Weitere Anpassungen wurden im internen Funktionsbereich der BTE-Tools durchgeführt. Nur so sind die erwähnten Anforderungen erfüllbar\footnote{Diese Änderungen sind für den Anwender nicht relevant und brauchen von ihm deswegen nicht weiter behandelt zu werden.}. 
%
\subsection*{Implementierung der Datenspeicherung}
%
Zur Implementierung der Speicherung des Testreports auf dem RAM werden zwei unterschiedliche Ansätze berücksichtigt. Der der erste Ansatz weist bestimmte Nachteile auf, deshalb wird auf diese nur kurz eingegangen. Die zweite Möglichkeit wird dahingegen ausführlicher behandelt, denn auf ihr basieren die Lösungsergebnisse der vorliegenden Aufgabe. 

Bei jedem der erwähnten Lösungsansätze ist eine geignete Kodierung der Daten in Form eines geigneten Protokolls notwendig, welches die Datenspeicherung auf dem RAM verwaltet.

\textbf{Report in Form einer Struktur (\texttt{stBteLogList}}):  

Der erste Ansatz, die Liste anhand einer Struktur abzuspeichern, wird durch \lstref{lst:structList} beschrieben. Dabei ist ersichtlich, dass der Datentyp \texttt{stBteLogList} aus einem 16-bit langen Eintrag (\textit{size}) und einer weiteren Struktur \verb|elem| vom Typ \texttt{stBteEventLog} besteht. Letztere enthält zwei weitere Datentypen (\textit{code} und \textit{data}). 
%
\begin{lstlisting}[style=C_colored_smallfont, caption = {Ausschnitt aus in Aufgabe 2 erstellten Sourcefile BteLogList.c}, label={lst:structList}]
typedef struct stBteEventLog 
{
  uint16 code;
  uint32 data;
} tBteEventLog;

typedef struct stBteLogList 
{
  uint16     size;
  tBteEventLog   elem[kBteLogList_size];
} tBteLogList;
\end{lstlisting}
%

Der Testreport wird auf Basis dieser beiden Strukturen im RAM des eingebetteten Prozessors abgelegt. Diese Struktur muss unterschiedliche Kennungen enthalten, welche zusammen das genannte Protokoll definieren. Damit ist eine hierachiche Trennung der gespeicherten Daten und deren Unterscheidung für eine geeignete Dekodierung gewährleistet. Tabelle \ref{tab:Protokoll1} zeigt eine beispielshafte Auswahl der verwendeten Kennungen.
%
\begin{table}[ht]
% title of Table
\centering 
% used for centering table
\begin{tabular}{c c c c}
% centered columns (4 columns)
\hline
\hline                        %inserts double horizontal lines
Kodierung & Beschreibung \\ [0.5ex]% inserts table 
%heading
\hline
0xFF & Kennung eines Testcases\\
\hline
0x21 & Kennung für 1. Datenelement\\
\hline
0x22 & Kennung für 2. Datenelement\\
\hline
0x23 & Kennung für 3. Datenelement\\
\hline
0x24 & Kennung für 4. Datenelement\\
\hline
0x25 & Kennung für 5. Datenelement\\ [1ex]      % [1ex] adds vertical space
\hline
%inserts single line
\end{tabular}
\caption{Verwendete Kennungen zur Unterscheidung der RAM-Bereiche, wo der Testreport gespeichert ist.}
\label{tab:Protokoll1}
% is used to refer this table in the text
\end{table}
%
\newpage
Wird ein neuer Testreport erstellt, dann wird am Anfang die Länge \texttt{size} von \texttt{tBteLogList} auf Null gesetzt. Dadurch werden alle alten Einträge der Liste überschrieben bzw. gelöscht. Im nächsten Schritt werden in Abhängigkeit der vorgegebenen Testcases die definierten Kennungen innerhalb der vorhandenen Elementen der Liste \texttt{elem} abgespeichert. 

Die einzelnen Elementen \texttt{elem} werden dabei in Abhängigkeit des Datentyps mithilfe von Bitverschiebungsoperationen so befüllt, dass dabei folgenden Informationen vorkommen:
%
\begin{table}[ht]
% title of Table
\centering 
% used for centering table
\begin{tabular}{c c c c}
% centered columns (4 columns)
\hline
\hline                        %inserts double horizontal lines
Variablenname & Bezeichnung \\ [0.5ex]% inserts table 
%heading
\hline
\texttt{testcaseID} & Testcase-ID-Nummer\\
\hline
\texttt{numParam} & die Anzahl an übergebenen Parameter\\
\hline
\texttt{type} & Event-Typ\\
\hline
\texttt{comp} & Component-ID-Nummer\\
\hline
\texttt{code} & Event-Code \texttt{code}\\
\hline
\texttt{time} & Zeitstempel\\
\hline
\texttt{data\_XYZ} & übergebene Parametern\\ [1ex]      % [1ex] adds vertical space
\hline
%inserts single line
\end{tabular}
\caption{Relevanten Daten eines Events bei einem beliebigen Testcase.}
\label{tab:relevDatenEvents}
% is used to refer this table in the text
\end{table}
%

Abbildung \ref{fig:Protocol1} zeigt, wie das Protokoll bei dieser Art der Abspeicherung des Testreports auf dem RAM des eingebetteten Prozessors implementiert wird. 
%
\begin{figure}[!htp]
\centering
\includegraphics[scale=0.8]{./Bilder/Protocol12.pdf}
\caption{Struktur des RAM-Speichers bei Implementierung des Testreports in Form eines \texttt{struct}-Datentyps.}
\label{fig:Protocol1}
\end{figure}
%

Nachteilig dabei ist, dass der Compiler die größe des Bereichs so groß wie der größte, in der Liste \texttt{tBteLogList} vorkommende Variablentyp festlegt. Jede Variable wird somit wie eine 32-Bit große Variable behandelt (\verb|uint32|). Der Compiler wird deshalb für jede Variable immer einen 32-Bit großen Speicherplatz reservieren. Dies führt zu Speicherplatz-Verschwendung, wenn es sich bei den abzuspeichernden Daten lediglich um 8-Bit große Variablen handeln sollte. 

Dies lässt sich dadurch vermeiden, dass spezielle Compiler-Einstellungen durchgeführt werden, was aber noch mehr Zeit in Anspruch nehmen würde.
\newpage
%
\section*{Zehnte Woche}
%
Während dieser Woche galt meine Arbeit weiterhin der Lösung der 2. Aufgabe. Die zweite Möglichkeit der Kodierung und Abspeicherung des Reports wird hierbei eingeführt und beschrieben. 

\textbf{Report in Form eines Byte-Arrays \texttt{BteLogArray}}: 

Der Report wird in Form eines normalen Arrays \texttt{BteLogArray} vom Typ \verb|uint8| im RAM des betrachteten Prozessors abgespeichert. 
Die verarbeiteten Informationen bei den Methodensaufrufen werden ebenfalls sequenziell innerhalb des Arrays abgelegt. Dabei richtet sich die Abspeicherung der Daten nach den in folgender Tabelle festgelegten Kennungen.
%
\begin{table}[ht]
% title of Table
\centering 
% used for centering table
\begin{tabular}{c c}
% centered columns (4 columns)
\hline
\hline                        %inserts double horizontal lines
Kodierung & Beschreibung \\ [0.5ex]% inserts table 
%heading
\hline                  % inserts single horizontal line
0xFF & Kennung eines neuen Testcases \\
% inserting body of the table
0x5C & Kennung für End of file \\
0x6E & Kennung für End of file  \\ [1ex]      % [1ex] adds vertical space
\hline
%inserts single line
\end{tabular}
\label{tab:Protokoll2}
\caption{Verwendete Kennungen zur Unterscheidung der RAM-Bereiche, wo der Testreport gespeichert ist.}
% is used to refer this table in the text
\end{table}
%

Offensichtlich werden dabei nur der Anfang und das Ende des Report gekennzeichnet. Die Daten, die bei den einzelnen Methodensaufrufe ebenfalls im Report abzuspeichern sind, lassen sich allein durch die Kenntnis der Anzahl an übergebenen Paratemern wieder rekonstruieren \footnote{Dies geschieht beim Dekodieren des Testreports anhand des PERL-Skripts, dessen Umsetzung noch beschrieben wird.}. Außerdem weiß man darüber Bescheid, dass bei jedem neuen Testcase die in Tabelle \ref{tab:relevDatenEvents} angegebenen Variablen auf dem Report auszugeben sind.

Da in der Regel die übergebenen Parameter und manche Daten, die auf dem Testreport vorkommen, nicht vom kleinsten Datentyp \texttt{uint8} sind sondern größer (\texttt{uint16} bzw. \texttt{uint32}), kann deren Inhalt nicht direkt in die einzelnen Einträge des Byte-Arrays passen. Vor der Abspeicherung müssen diese Informationen deshalb so zerlegt und angepasst werden, dass sie immer in den 8-Bit großen Einträgen des genannten Arrays hinein passen. 

Diese Datenanpassung wird mithilfe der in \lstref{lst:ArrayList} gezeigten Methoden durchgeführt. Dabei werden die benötigten Daten nicht nur zerlegt, sondern auch direkt in dem Array gespeichert. 
\clearpage
\begin{lstlisting}[style=C_colored_smallfont, caption = {Ausschnitt aus BteLogList.c}, label={lst:ArrayList}]

void BteLogList_Serialize32(uint32 data)
{
  BteLogArray[kBteLogArray_position++] = (uint8)(data>>24);
  BteLogArray[kBteLogArray_position++] = (uint8)((data>>16) & 0xFF);
  BteLogArray[kBteLogArray_position++] = (uint8)((data>>8) & 0xFF);
  BteLogArray[kBteLogArray_position++] = (uint8)(data & 0xFF);
}

void BteLogList_Serialize16(uint16 data)
{
  BteLogArray[kBteLogArray_position++] = (uint8)((data>>8) & 0xFF);
  BteLogArray[kBteLogArray_position++] = (uint8)(data & 0xFF);
}
\end{lstlisting}

In Abbildung \ref{fig:Protocol2} wird ein Beispiel der Anordnung der gespeicherten Daten im RAM gezeigt. Variablen, die in kleineren 8-bit Datenfeldern zerlegt wurden, sind \verb|testcaseID|, \verb|time| und \verb|dataXYZ|. Der Inhalt der betrachteten Variable \verb|BteLogArray|, wo der Testreport sich befindet, wird dabei desto größer, je mehr Testfälle, Methodensaufrufe und übergebenen Parametern bei den zu testenden Funktionen vorkommen. 
%
\begin{figure}[!htp]
\centering
\includegraphics[scale=0.7]{./Bilder/Protocol2_cropped.pdf}
\caption{Struktur des RAM-Speichers bei Implementierung des Testreports in Form eines \texttt{uint8}-Array-Datentyps.}
\label{fig:Protocol2}
\end{figure}
%

Auf dieser Art und Weise wird mit den knappen, zur Verfügung stehenden Hardwareressourcen möglichst sparsam umgegangen. Jedes Feld des Arrays ist dadurch mit relevanten Daten vom Testreport befüllt, was dazu führt, dass möglichst wenig Speicherplatz verschwendet wird.

Nach einer erfolgreichen Speicherung der Daten in den RAM des eingebetteten Systems, sieht der Speicherbereich wie im Bild \ref{fig:EclipseHardwareMem} aus. Mithilfe des GDB-Debuggers ist es dann möglich, den relevanten Speicherbereich direkt als Binärdatei auf den lokalen PC zu exportieren. Dazu ist es deswegen notwendig, dass ein Hardware-Debugger zur Versfügung steht. Auf Basis dieser Datei und einer \verb|PERL|-Anwendung wird die Rekonstruktion des entsprechenden Reports angesetzt. Dieser Ansatz wird im nächsten Kapitel näher erklärt.
%
\begin{figure}[!htp]
\centering
\includegraphics[scale=0.7]{./Bilder/EclipseHardwareMem.pdf}
\caption{Eclipse-Funkitonalität zur Verwendung vom GDB-Debugger. Dabei lässt sich ein bestimmter Speicherbereich vom eingebetteten Prozessor entnehmen und als Binärdatei auf dem lokalen Rechner abspeichern.}
\label{fig:EclipseHardwareMem}
\end{figure}
%
\clearpage
%
\section*{Elfte Woche}
%
\subsubsection*{Dekodierung und Rekonstruktion eines XML-Testreports}
%
Ein Ansatz, um aus der Binärdatei ein Report zu erstellen, ist, diese Datei mithilfe einer in einer Skriptsprache programmierten Anwendung zu analysieren und verarbeiten. Entsprechende Algorithmen kümmern sich um die Dekodierung und Ausgabe der Daten als ein XML-File. Der auf dieser Art und Weise erstellte Report soll letztendlich bis auf kleine Details im Text genauso aussehen, wie ein Testreport, welcher mithilfe des BTE-Frameworks auf dem PC erstellt würde. 

Die Main-Methode \verb|ConvertBin2Vtr| des erstellten \verb|PERL|-Skripts wird in \lstref{lst:PERL_XMLRepMain} gezeigt. Die Struktur dieser Methode zeigt explizit die Struktur der gesammten programmierten Anwendung. 
%

\begin{lstlisting}[style=PERL_st, caption = {PERL-Skript zum Einlesen bzw. zur Verarbeiten einer Binärdatei.\\ Anschließend wird ein Testreport aus den gewonnenen Daten erstellt.},label={lst:PERL_XMLRepMain}]
# Main function
sub ConvertBin2Vtr
{
  # read the binary file containing the data of the data of the test report
  my $binFile_path = $ARGV[0];
	# read the path where the report file has to be stored
  my $vtrFile_path = $ARGV[1];
  
  # read the transformation rules from the configuration file
  LoadEventConfig($ARGV[2]);

  # get the relevant data
  GetBinaryContent($binFile_path);

  # process the binary data and write to vtr
  OpenVtr($vtrFile_path);
  ProcessBinaryData();
  CloseVtr();
}
\end{lstlisting}
%

In Zeile 5 wird die Binärdatei über das Kommando \texttt{\$ARGV[0]} eingelesen. Dieser Aufruf bezieht sich auf das 1. Argument, welcher dem programmierten \verb|PERL|-Skript übergeben wird. Dies kann über die Ausführung eines sogenannten Batch-Skripts ausgeführt werden. Die Batch-Funktionalitäten ähneln den Funktionalitäten der Windows-Kommandozeile. Wie der programmierte \verb|PERL|-Skript ausgeführt und die Binärdatei geladen werden können, wird bespielhaft anhand eines Batch-Skript in \lstref{lst:Batch} gezeigt.
%
\newpage
%
\begin{lstlisting}[style=Batch_st,caption = {Batch-Aufruf vom erstellten \texttt{PERL}-Skript. Dabei ist ersichtlich wie nicht nur der \texttt{PERL}-Skript ausgeführt wird, sondern auch weitere Files wie die Binärdatei, ein Userfile und das anschließend auszugebende Reportfile.},label={lst:Batch}]
@echo off
rem the following command can be used if the files in the parameter lies in the same path like the perl file
perl bin2xml_v2.pl test.bin AnwenderFile1.txt BteReport_Log.xml
pause
\end{lstlisting}
%
Desweiteren muss nach dem Einladen der Binärdatei eine entsprechende Vorvearbeitung derselbe stattfinden. Dies wird in Zeile 13 vom \lstref{lst:PERL_XMLRepMain} durchgeführt und ist deswegen notwendig, weil die relevanten Daten des Testreports nicht im gesammten \texttt{BteLogArray} enthalten sind, diese nur ein Teil davon belegen. Die restlichen Daten sind deshalb zu entfernen.

Die in Zeile 17 gezeigte Methode \texttt{ProcessBinaryData()} beinhaltet die eigentliche Dekodierung der Daten und Erstellung des Testreports. Im Anschluss der Dekodierung der Daten wird die Testreport-Datei auf die Festplatte gesichert.

Die oben genannten Schritten, die in der Main-Methode der \verb|PERL|-Anwendung durchgeführt werden, sind in Form einer State-Maschine in Abbildung \ref{fig:StateMaschPERL} dargestellt. In dem Zustand \textit{AnalyseReadByte} überprüft der Suchalgorithmus die Natur des eingelesenen Bytes. In Anbhängigkeit derselben gibt es Transitionen in den benachbarten Zuständen, wo die Daten dekodiert werden und der Testreport gleichzeitig aktualisiert wird.

Ein Ausschnitt vom erstellten \verb|PERL|-Skript kann in \lstref{lst:PERL_XML_Binary} gefunden werden. Das oben gezeigte Diagramm ergänzt die Software-Spezifikation dienen.
%\begin{landscape}
\begin{figure}[!htp]
\centering
\includegraphics[scale=0.9]{./Bilder/StateMaschPERL_cropped.pdf}
\caption{State-Chart-Diagramm, welches die Funktionsweise der erstellte PERL-Anwendung näher beschreibt.}
\label{fig:StateMaschPERL}
\end{figure}
%\end{landscape}
%
\newpage
%
\section*{Zwölfte Woche}
%
In der vorliegenden Woche war meine Aufgabe das \verb|PERL|-Programm zu dokumentieren und besser zu strukturieren. Nur so ist es möglich, in der Zukunft das erstellte bzw. modifizierte Tool zu pflegen und warten. 
%
\subsubsection*{Gesamte Struktur des erweiterten Anwendungfalls}
%
Der in \figvref{fig:BTEUseCase} gezeigte Anwendungsfall \textit{execute test on embedded device} konnte durch die Anpassungen der vorhandenen Struktur des BTE-Tools und die Erstellung eines \verb|PERL|-Skripts realisiert werden. Seine gesammte Funktionalität wird in Abbildung \ref{fig:BTELogListStruktur} in Form eines Klassendiagramms dargestellt.

Die gelb markierten Klassen stellen die bereits vorhandenen Funktionalitäten dar, die gegebenenfalls modifiziert werden mussten. Diese sind ebenfalls in \figvref{fig:BTELogListold} dargestellt.

Die weißen Klassen erweitern den Funktionsumfang und wurden zur Lösung der vorliegenden Aufgabe. Diese ermöglichen die Lauffähigkeit des BTE-Tools auf einem beliebigen eingegebetteten System und die Erstellung eines entsprechenden Testreports.

Dabei ist zu erkennen, dass das gesammte BTE-Tool auf dem eingebetteten Echtzeitsystem läuft und dabei über das erstellte \verb|LogList|-Modul die relevanten Informationen vom Testreport auf den LogList-Array speichert. Das Debugger-Modul kümmert sich um das Extrahieren der Binärdatei vom RAM des betrachteten Systems, wobei es anzumerken ist, dass dies manuell erfolgen muss. 

Auf der PC-Seite befindet sich neben der extrahierten Binärdatei die programmierten \verb|PERL|-Anwendung, welche sich zusätzlich eines vom User vorgegebenen Konfigurationsfiles bedient, um den gewünschten Testreport zu erstellen.
%
%\begin{landscape}
\begin{figure}[!htp]
\centering
\includegraphics[scale=0.8]{./Bilder/BTELogList_cropped.pdf}
\caption{Klassendiagramm zur Ergänzung der Softwarespezifikation des erweiterten BTE-Tools. Dabei können die funktionalen Zusammenhänge zwischen den alten und neuen Modulen erkannt werden.}
\label{fig:BTELogListStruktur}
\end{figure}
%\end{landscape}
%
\section{Validierung und Ergebnisse der 2. Aufgabenstellung}
%
Um die Gültigkeit der programmierten Anwendungen zu überprüfen, werden zwei Testreports einer beliebigen Software-Komponente erstellt.

Die Tests werden jeweils auf dem PC und der in \figvref{fig:discovery} gezeigten Hardware durchgeführt. Am Ende jeden Tests entstehen zwei unabhängige Binärdateien, die die Testreports enthalten. Auf dem PC werden die zwei Dateien mithilfe der \verb|PERL|-Anwendung analysiert und in ein entsprechendes XML-File konvertiert. Beide Dateien werden in Abbildung \ref{fig:reports} miteinander vergliechen. Dabei stellt man fest, dass beide Reports die gleiche Eigenschaften aufweisen, was auf die Korrektheit der implementierten Anwendung schließen lässt.
%
\begin{landscape}
\begin{figure}[!htp]
\centering
\includegraphics[width=200mm,height=150mm]{./Bilder/reports.pdf}
\caption{Testreports, die aus zwei unterschiedlichen Binärdateien erstellt worden sind. Die eine Binärdatei wird nach Testdurchführung auf PC und die zweite auf dem eingebetteten Prozessor erstellt.}
\label{fig:reports}
\end{figure}
\end{landscape}
%