\chapter{Arbeitsbericht}
%
\section{Erste Woche}
%
\subsection{Wochenübersicht}
%
Tabelle
%
\subsection{Beschreibung}\label{Be1Woche}
%
Am ersten Tag meiner Tätigkeit bei Vector Informatik bekam ich die Gelegenheit die Firma und ihre unterschiedlichen Abteilungen näher kennen zu lernen. Es war erforderlich, an einer ausführlichen Präsentation über die Firma und die unterschiedlichen Abteilungen teilzunehmen. Dabei konnte ich ebenfalls Mitarbeiter kennen lernen, für die dieser auch ihr erster Tag bei Vector war.
%
\begin{figure}[htp]
\centering
%\def\svgwidth{scale=0.4}
%\input{./Bilder/Zeichnung1.pdf_tex}
\includegraphics[scale=1]{./Bilder/Zeichnung1.pdf}
\caption{Zeichnung1}
\label{fig:Zeichnung1}
\end{figure}

Die Softwareabteilung (ADP) gab uns u.a. zahlreiche Einblicke in Themen wie vorhandene Software-Packete, Software-Sicherheit und den richtigen Umgang mit den von Vector zur Verfügung gestellten Programmen und Anwendungen. 

Mein interner Betreuer, der Herr Dipl. Ing. Markus Schwarz, stellte mir eine die Abteilung vor und begleitete mich an meinen Arbeitsplatz.

Während der ersten Tagen galt meine Arbeit der Einarbeitung und Verwendung mancher Software Tools, die von jedem Vector-Mitarbeiter zu verwenden sind. Unter anderem wird dabei eine eigene Umgebung verwendet, um die Arbeitsstunden zu dokumentieren. Diese ist in Bild \ref{fig:viTime} beispielhaft zu sehen.
%
\begin{figure}[!htp]
\centering
\includegraphics[scale=0.5]{./Bilder/vi.pdf}
\caption{viTime}
\label{fig:viTime}
\end{figure}
%

Diese sind unter anderem TortoiseSVN: Hier bitte eine kurze Beschreibung von Tortoise geben. Du kannst auch dazu irgendeine Präsentation von ADP benutzen, suche im Intranet danach. 
%
\begin{figure}[htp]
\centering
\includegraphics[scale=1]{./Bilder/Repo.pdf}
\caption{Tortoisegit}
\label{fig:Tortoisegit}
\end{figure}
%
\subsubsection{Erste Aufgabenstellung}
%\paragraph{Erste Aufgabenstellung}
%
In den folgenden Tagen wurde mir die 1. Aufgabe meiner Arbeitstätigkeit bei Vector vorgestellt:
%
\begin{Aufgabenstellung}
Sich erstens mit den Konzepten des MISRA-C-Kodierungsstandards vertraut machen. Anschließend sollten mögliche Rückschlüsse gezogen werden, wie umfangreich ein Umstieg von dem aktuell in der Firma geprüften Kodierungsstandard MISRA C:2004 in den neuen Standard MISRA C:2012 ist.
\end{Aufgabenstellung}
%
\paragraph*{\uppercase{MISRA-C-Standard und Gründe für seine Einführung}}\label{MISRAC}
%
Die Programmiersprache C wurde im Jahr 1972 von Dennis Ritchie und Brian W. Kernighan entwickelt~\cite{CLang}. 

Im Bereich eingebetteter Systeme bietet C den Programmierern viele Möglichkeiten direkt auf die Speicherbereiche der Hardware zuzugreifen. Dadurch entsteht u.a. die Gefahr, bewusst oder unbewusst viele systemeingene Speicheradressen zu manipulieren und zu einem ungewünschten allgemeinen Systemverhalten zu führen. Weitere kritische Aspekte von C als Programmiersprache können in~\cite{MasterThMISRA} nachgelesen werden.

Der sogenannter MISRA C-Standard hilft beispielsweise dabei, den bekannten Nachteilen der Programmiersprache entgegenzuwirken. Eine kurze Einführung wird im folgenden gegeben.

MISRA-C hat seinen Ursprung in der Automobilindustrie und wurde durch die britische \glqq The Motor Industry Sofrware Reliability Association\grqq\ eingeführt. Die erste Version wurde in 1998 mit dem Ziel veröffentlich, eine positive Auswirkung auf die Verwendung von eingebetteter Software innerhalb der britischen Automobilindustrie zu haben~\cite{MISRA2004}. Seitdem ist der MISRA-Standard nicht nur im Automobilsektor eingesetzt worden sondern auch in Bereichen wie Raumfahrtindustrie oder Medizintechnik. 

Eine Vielzahl an Regeln sind dabei veröffentlicht worden, um robusteren und zuverlässigeren Embedded C-Code zu produzieren. Außerdem wird damit erreicht, dass die erstellten Software-Produkte wiederverwendbar und portabler sind~\cite{MISRA2012}. 

Der zahlreiche Einsatz der MISRA C:2004-Version über die Jahre hat vielfältige Ergänzungen und Verbesserungen als Folge gehabt. Die Regeln sind jetzt bei MISRA C:2012 so definiert und beschrieben, dass die Begründungen für ihre Nutzung umfangreicher wurden. 

Die Kodierungsstandards von Vector Informatik richten sich momentan noch nicht nach der aktuellen MISRA C:2012-Version~\cite{MISRACodeMetric}. Der Hauptgrund liegt darin, dass bei dem neuen Standard die Mehrheit der Regeln umnummeriert bzw. umstrukturiert wurden. Das bedeutet, dass sich ein Umstieg von der letzten MISRA-C:2004-Version auf die aktuelle Version nicht direkt durchführen lässt, ohne davor einen entsprechenden Aufwand zu investieren.
%
\begin{figure}[!htp]
\centering
\includegraphics[scale=0.1]{./Bilder/MISRAoverall.png}
\caption{MISRA: wenn ich dieses Bild nicht verstehen kann, dann lieber weglassen}
\label{fig:MISRA}
\end{figure}
%
Die OEMs fordern seit der Einführung von MISRA C:2012, dass die in ihren Produkten eingesetzten embedded software mit dieser Version des Standards konform gehen soll.

Vektor und somit die Abteilung PES sind aus diesem Grund darauf angewiesen, in naher Zukunft einen Umstieg in die neue Version zu ermöglichen. Da dies sich nicht ohne Weiteres umsetzen lässt, muss dazu eine detaillierte Analyse vor allem über die Kompatibilität zwischen den beiden Versionen (2004 und 2012) durchgeführt werden, deren Ergebnisse in den Kapitel \ref{sec:DritteWoche} bzw. \ref{sec:VierteWoche} ausführlich beschrieben werden.
%
\section{Zweite Woche}
%
\subsection{Wochenübersicht}
%
Tabelle
%
\subsection{Beschreibung}
%
\subsubsection{Durchführung der ersten Aufgabenstellung}
%\paragraph{Durchführung der ersten Aufgabenstellung}
%
Eine genaue Rechnerche über die oben erwähnten Standards war notwendig, um nicht nur einen Einblick in das Thema zu gewinnen sondern auch die technischen Zusammenhänge zu verstehen.

Im Folgenden wird eine kurze Einführung in die neuen Features angegeben, die von der MISRA C:2012-Version unterstützt werden und wie diese strukturiert ist.
%
\paragraph*{\uppercase{MISRA C:2012}}
%
Im Gegensatz zu den ersten MISRA-Versionen fordert MISRA C:2012, dass programmiertes C Code mit dem Standard \textsc{C99} \footnote{ISO Standard for the C language ISO/IEC 9899:1999~\cite{MISRA2012}} konform geht. Außerdem sind einige neue Regeln hinzugekommen, die sich hauptsächlich auf \textsc{C99} beziehen, einige wenige wurden umformuliert oder sogar entfernt~\cite{WarMISRAC}.

Bei den ersten MISRA-Versionen sind die Regeln in zwei Kategorien eingeteilt: 
notwendige (required) und empfohlene (advisory) Regel. Die ersten sind erforderliche Anforderungen an dem Programmierer. Die empfohlenen Regeln können eingehalten werden, müssen demgegenüger aber nicht.

Die einzelnen Regeln bestehen bei MISRA C:2012 aus mehreren Teilen:

\begin{itemize}
\item Erweiterte Erläuterungen (Amplification): \\
umfangreichere Beschreibeung der betrachteten Richtlinie.
\item Begründung (Rationale): \\
Erläuterung, warum die Regel benötigt wird.
\item Ausnahmen (Exceptions): \\
Beschreibung der Fälle, bei denen die betrachtete Regel nicht gilt.
\item Beispiele (Examples): \\
Beispiele, wie man die Regel anwenden kann.
\end{itemize}

\textsc{MISRA C:2012} hat somit eine zusätzliche Kategorie eigeführt, nämlich die zwingend erforderliche Regel (mandatory). Unter keinen Umständen dürfen solche Regel verletzt werden.

Dem Begriff der Durchsetzbarkeit einer Regel wurde besondendere Aufmerksamkeit geschenkt. Die Durchsetzbarkeit besagt, wie gut sich eine Regel mithilfe einer statischen Analyse prüfen lässt. Letzteres ist von hoher Bedeutung, denn die automatische Prüfung von Regeln spart viel Zeit, wirkt sofort, ist zuverlässig, wiederholbar und konsistent~\cite{WarMISRAC}. Dabei wird beispielsweise die Notwendgikeit verringert, von der manuellen Codeanalyse abhängig zu sein. 

Die Maßnahmen, die diesbezüglich bei der neuen MISRA-Version getroffen wurden, sind im Folgenden erläutert\footnote{Siehe dazu~\cite{MISRA2012}, Unterkapitel 6.6}:

\begin{itemize}
\item Es besteht nun ein Unterschied zwischen Regeln und Anordnungen (Directives). Regeln lassen sich direkt durch eine Analyse des Quellcodes durchsetzen (Siehe die obige Definition von Durchsetzbarkeit). Anordnungen sind im Gegensatz dazu nicht präzise definiert, so dass ihre Einhaltung  eine genauere Untersuchung u.a. der Funktionsanforderungen benötigt.
\item Eine Regel kann innerhalb einer \textit{einzelnen Übersetzungseinheit} (Single Translation Unit) oder eines \textit{Systems} (System) analysiert werden. Diese Begriffe geben den nötigen Aufwand einer Analyse wieder, um eine Regel zu überprüfen.
\end{itemize}

Abbildung \ref{fig:MISRA2004} gibt die obigen Zusammenhänge zwischen den relevanten MISRA-Versionen wieder.
%
\begin{figure}[!htp]
\centering
\includegraphics[scale=0.7]{./Bilder/MISRA2004.pdf}
\caption{Vergleich zwischen den akteullen MISRA-Versionen. In Anlehnung an~\cite{WarMISRAC}}
\label{fig:MISRA2004}
\end{figure}
%

Um den Nachweis liefern zu können, wie konform ein spezifisches Software-Projekt mit dem gesamten MISRA-C-Regelwerk geht, wird in der Regel ein ausgewähltes statisches Analysewerkzeug eingesetzt. Eine ausführliche Beschreibung über dieses Thema wird im Folgenden gegeben.
%
\section{Dritte Woche}\label{sec:DritteWoche}
%
\subsection{Wochenübersicht}
%
Tabelle
%
\subsection{Arbeitsbericht}
%
\paragraph*{Verwendetes statisches Analysewerkzeug QA-C}\label{QAC7Einf}
%
Bei der Vector Informatik GmbH wird zurzeit noch das Programm QA-C der Firma QA-Systems verwendet, um die genannte statische Code-Analyse ihrer Software-Produkte durchzuführen~\cite{MISRACodeMetric}. Das genannte Tool ist eine kommerzielle Software zur automatisierten Überprüfung eines fetgelegten, firmenspezifischen Programmierstandards~\cite{QAC_Iseite}.

QA-C bietet die Möglichkeit eine statische Code-Analyse in 3 Phasen durchzuführen. In der 1. Phase der Analyse wird der Quellcode auf Konformität mit definierten Standards wie beispielsweise \textsc{C99} untersucht. Die drauf folgende Analyse (secondary analysis) ist ein optionale Erweiterung, bei der sich in der Regel industrie-, firmeneigene oder standardspezifische Tests durchführen lassen (MISRA-C:2004 bzw. MISRA-C:2004). In der dritten Phase wird die so genannte cross-module-Analyse durchgeführt, welche die aus dem Source Code extrahierten \textit{translation units} untersucht. Für eine genaue Beschriebung der QA-C-Funktionaliäten sei auf~\cite{QAC70WinUserGuide} verwiesen. 

Abbildung \ref{fig:QACfunc} zeigt einen Überblick über die funktionalen Beziehungen der Analyse-Software und die unterschiedlichen Ergebnisse einer beliebigen Beispielanwendung.

%
\begin{figure}[!htp]
\centering
\includegraphics[scale=1.2]{./Bilder/QAC_functions.pdf}
\caption{QA-C-Funktionalitäten. In Anlehnung an~\cite{QAC70WinUserGuide}.}
\label{fig:QACfunc}
\end{figure}
%

Dabei kann man erkennen, dass beim Teil \textit{Configuration} bestimmte Files notwendig sind, damit ein QA-C-Projekt richtig initialisiert und überhaupt die Analyse stattfinden kann. Diese Einstellungsdateien werden als \textit{personalities} bezeichnet und werden im folgenden näher beschrieben~\cite{QAC70WinUserGuide}: 

\begin{itemize}
\item Compiler Personality ($*.p\_c$): \\
definiert die Einstellungen für den Compiler, der bei der Entwicklung der Source Files verwendet wird. 
\item Analysis Personality ($*.p\_a$): \\
definiert die Analyse-Einstellungen, die projektabhängig sind wie Include-Pfade, usw.  
\item Message Personality ($*.p\_s$): \\
Einstellungen bezüglich der für die Untersuchung relevanten QA-C-Nachrichten.
\end{itemize}

Die Struktur bzw. der Aufbau der obigen Dateien wird vom Hersteller (QA-Systems) vorgegeben. Man ist deswegen zur korrekten Anwendung auf die Dokumentation der Software angewiesen. 

Ich durfte eigenständig eine statische Analyse einer einzelnen BSW-Komponente (Single Component) mit der betrachteten QA-C-Software durchführen und dabei die oben eingeführten Einstellungsdateien verwenden bzw. angeben. Die Analyse erfolgte mithilfe der Version QA-C 7.0, für die die Abteilung über eine Lizenz verfügt. Die Analysen, die mit QA-C durchgeführt werden können, beschränken sich nicht nur auf Kodierungsregeln wie beispielsweise die MISRA-C-Regeln. Dabei lassen sich auch funktionale und technische Fehler, potentielle Bugs sowie auch qualitative Schwachstellen im Code~\cite{QAC70WinUserGuide} erkennen. 

Die entsprechenden Ergebnisse dieser einführenden Analyse sind in \figref{fig:QAC7Single1} bzw. \figref{fig:QAC7Single} dargestellt. 
%
\begin{figure}[!htp]
\centering
\includegraphics[scale=0.55]{./Bilder/QAC7Single1.pdf}
\caption{Analyse einer erste BSW-Komponente mit QA-C7.}
\label{fig:QAC7Single1}
\end{figure}
%
\begin{figure}[!htp]
\centering
\includegraphics[scale=0.45]{./Bilder/QAC7Single.pdf}
\caption{Ergebnisse der Analyse vom betrachteten Source Code.}
\label{fig:QAC7Single}
\end{figure}
%

Um die Analyse des Projekts zu starten, wurden die folgenden Listings erstellt: 
%
\begin{lstlisting}[basicstyle=\ttfamily\scriptsize, caption = {Compiler personality file QA-C.p\_c}, label={lst:QAC_p_c}]
-i "C:\Program Files (x86)\Microsoft Visual Studio 10.0\VC\Include" 
-i "C:\Program Files (x86)\Microsoft SDKs\Windows\v7.0A\Include" 
-q "C:\Program Files (x86)\Microsoft Visual Studio 10.0\VC\Include" 
-q "C:\Program Files (x86)\Microsoft SDKs\Windows\v7.0A\Include" 
-it "ptrdiff_t=int"
-it "wchar_t=unsigned short"
-d "__alignof(type)=1"
-d "__based(type)="
-d "__cdecl="
-d "__COUNTER__=1"
-d "__declspec(arg)="
-d "__declspec=_ignore_paren"
-d "__event="
-d "__far="
-d "__fastcall="
-d "__forceinline=inline"
-d "__FUNCDNAME__=__FUNCTION__"
-d "__FUNCSIG__=__FUNCTION__"
...
\end{lstlisting}

\begin{lstlisting}[basicstyle=\ttfamily\scriptsize, caption = {Analysis personality file QA-C.p\_s}, label={lst:QAC_p_s}]
-rem "ShellExe=C:\Program Files (x86)\PRQA\QAC-7.0\m2cm\bin\qacsa_m2cm.exe"
-rem "EnablePostAnalysis=1"
-rem "ShellParams=%Q %F -forget cmaf"
-up "d:\uti\CDK\Tools\QAC\m2cm\messages\" 
-usr .m2cm
-l+
-format "%?u==0%(%q%:%?F%(%F%)%)(%l,%c) : %?u==0%(%?h%(Err%:Msg%)%:-->%)(%g:%N) %R(%u,  )%t MisraId %v"
-max 0
-m+
-st+
-hdr-
-summary-
-references+
-onelineonly-  
-hiddenwarnings-

-o 9
-o 40
-o 41
-o 42
-o 97
-o 159
...
\end{lstlisting}

\begin{lstlisting}[basicstyle=\ttfamily\scriptsize, caption = {Message personality file QA-C.p\_a}, label={lst:QAC_p_a}]
-il 0
-i "D:\usr\Task_01\QAC_Eval\SimpleComponent\Code\Relevant"                    
-i "D:\usr\Task_01\QAC_Eval\SimpleComponent\Code\Includes"                    
-q "D:\usr\Task_01\QAC_Eval\SimpleComponent\Code\Includes"         
-d "__MSVC_RUNTIME_CHECKS"
-d "_CHAR_UNSIGNED"
-d "_CONSOLE"
-d "_CPPRTTI"
-d "_DEBUG"
-d "_DLL"
-d "_MT"
-d "_UNICODE"
-d "CDK_CHECK_MISRA"
-d "UNICODE"
-d "VECTOR_DEBUG"
-sty exdented
-tab 2
-en ASC
-maxerr 0
...
\end{lstlisting}

Mithilfe dieser Dateien fiel es mir einfacher zu verstehen, wie die genannten Einstellungen über die \textit{personality files} durchzuführen sind. In \lstref{lst:QAC_p_c} lässt sich beispielweise erkennen, wie bei den QA-C-Compiler-Optionen $-i$ die Suchpfade für den beim analysierten Projekt verwendeten Compiler vorgegeben werden. Analog lassen sich projektabhängige Include-Pfade am Anfang der \textit{personality file} QA-C.p\_a (siehe \lstref{lst:QAC_p_a}) angeben.

Im Gegensatz zur QA-C vorgestellten Version 7.0 werden von der 9.0 Version beide relevanten Versionen des MISRA-Standards (2004 und 2012) unterstützt. Eine genaue Beschreibung dazu wird im folgenden Kapitel gegeben.
%
\paragraph*{Lösungsansatz zum Vergleich der relevanten MISRA-Versionen}
%
Das Ziel, welches man beim Lösen dieser Aufgabe verfolgt, ist eine Schlussfolgerung daraus zu ziehen, ob ein automatisierter Umstieg auf den aktuellen MISRA 2012-Standard mit vertretbarem Aufwand möglich ist. Beim genannten Umstieg geht es vor allem um die Frage, ob die Struktur der Software-Produkte, die bisher bei Vector erstellt wurden, beibehalten werden kann oder diese wegen neu eingeführter bzw. geänderter MISRA-Regeln anzupassen ist. 

Als Beurteilungskriterium könnten die Ergebnisse eines Vergleichs zwischen den betrachteten MISRA C- bzw. QA-C-Versionen dienen. Würde man dabei feststellen, dass in den neuen Versionen keine großen Änderungen in der Definition oder Unterstützung der Regeln vorkommen, dann wäre der Umstieg relativ einfach möglich. Sind im Gegenteil dazu viele MISRA-Regeln beispielsweise neu hinzugekommen, gelöscht oder umgestrukturiert worden, dann würde der dabei entstehende Aufwand ansteigen.

Um eine erste Analyse durchzuführen, sollten erstens die Unterschiede der beiden betrachteten MISRA Standards genauer untersucht und gegenüber gestellt werden. Zweitens  sind die QA-C Versionen 7.0 und (die aktuelle) 9.0 in Bezug auf unterstützte Regeln und Toolnutzung miteinander zu vergleichen. Der Zweiter Punkt ist wichtiger im Bezug auf den oben genannten Umstieg zwischen den MISRA-Versionen, wie in den folgenden Kapitel erläurtert wird.

%Wie schon oben einführend erwähnt verfügt die PES-Abteilung über eine Lizenz der QA-C 7.0-Version, mit deren Hilfe die Konformität von eingebetteter Software mit dem MISRA-C:2004-Standard geprüft wird. 
\newpage
%
\section{Vierte Woche}\label{sec:VierteWoche}
%
\subsection{Wochenübersicht}
%
Tabelle
%
\subsection{Arbeitsbericht}
%
Im Gegensatz zu den von QA-C verwendeten Richtlinien zur Prüfung von MISRA-Regeln braucht man kein direkter Vergleich der MISRA-Versionen durchzuführen. Ein solches Dokument wurde nämlich bereits von der britischen \glqq The Motor Industry Sofrware Reliability Association\grqq~veröffentlicht~\cite{Addendum1}. Eine Registrierung auf der Internetseite der MISRA-Institution ist erforderlich gewesen, um Zugang zum Dokument zu erlangen.

In \figvref{fig:Addendum1} ist ein kleiner Abschnitt des genannten Dokuments zu sehen, wo die Gegenüberstellungen der beiden betrachteten MISRA-Standards gezeigt sind. 

%
\begin{figure}[!htp]
\centering
\includegraphics[scale=0.45]{./Bilder/Addendum1.pdf}
\caption{Rule mapping MISRA C:2004 $\rightarrow$ MISRA C:2012. Entnommen aus ~\cite{Addendum1}}
\label{fig:Addendum1}
\end{figure}
%
%%
%\begin{figure}[htp]
%\centering
%\includegraphics[scale=0.75]{./Bilder/Addendum2.pdf}
%\caption{Rule mapping MISRA C:2012 $\rightarrow$ MISRA C:2004. Entnommen aus ~\cite{Addendum1}}
%\label{fig:Addendum2}
%\end{figure}
%%
\newpage
In \tabvref{tab:TabMisra1} bzw. \tabvref{tab:TabMisra2} werden die Ergebnisse einer ersten groben Analyse des in Abbildung \ref{fig:Addendum1} gezeigten Dokuments. Dabei ist zu erkennen, dass sowohl das Mapping \linebreak MISRA C:2004 $\rightarrow$ MISRA C:2012 als auch MISRA C:2012 $\rightarrow$ MISRA C:2004 wichtige Hinweise auf Veränderungen der Regeln liefern können. Die Bewertungskriterien sind so gewählt, dass diese eine gemeinsame Eigenschaft der neuen bzw. alten Regeln wiederspiegeln. 
%
\begin{longtable}{|l|l|}
\hline
\textbf{Eigenschaft der Regel} & \textbf{Anzahl an betroffenen Regeln} \\
\endhead
\hline
Gelöscht & 9 \\
\hline
<group prefix>-Nummer gleich geblieben & 38\\
\hline
<group prefix>-Nummer geändert & 95\\
\hline
Regel wurde in mehreren Regeln unterteilt & 15 \\
\hline
Regel wurde in Anordnung (directive) &\\umgewandelt & 19 \\
\hline
\caption{Relevante Zusammenhänge aus Rule mapping MISRA C:2004 $\rightarrow$ MISRA C:2012.}
\label{tab:TabMisra1}
\end{longtable}
%
\begin{longtable}{|l|l|}
\hline
\textbf{Eigenschaft der Regel} & \textbf{Anzahl an betroffenen Regeln} \\
\endhead
\hline
neu eingeführt & 37\\
\hline
Regel fasst mehrere alte Regeln zusammen & 19 \\
\hline
\caption{Relevante Zusammenhänge aus Rule mapping MISRA C:2012 $\rightarrow$ MISRA C:2004}
\label{tab:TabMisra2}
\end{longtable}
%

Eine weitere Untersuchung über die Unterschiede zwischen den MISRA-Versionen war mithilfe des genannten Addendum-Dokuments nicht notwendig. 

Vielmehr sollte man sich auf die im Laufe der Zeit durchgeführten Änderungen zwischen QA-C-Versionen konzentrieren, da über dieses Tool die MISRA-C-Regeln bei den Projekten geprüft werden. 

Ziel ist es somit, bestimmte Muster festzulegen, die diejenigen relevanten Änderungen beschreiben, die von der Version 7.0 bis 9.0 entstanden sind.

Werden viele Änderungen bei der Toolnutzung und der in QA-C unterstützten MISRA-Prüfung festgestellt, dann kann sich der gewünschte automatisierte Umstieg als umständlich erweisen.

Bei der Analyse sind 6 relevanten release notes ausgewählt und einer ausführlichen Analyse unterzogen. Diese Dokumente beschreiben sehr gut den erwähnten Änderungsverlauf.

Die in \figvref{fig:QAC7_9Zusam} gezeigte Excel-Tabelle zeigt das Ergebnis der durchgeführten Untersuchung.
%
\begin{landscape}
\begin{figure}[!htp]
\centering
\includegraphics[scale=0.55]{./Bilder/QAC7_9Zusam.pdf}
\caption{QAC}
\label{fig:QAC7_9Zusam}
\end{figure}
\end{landscape}
%

Dabei ist auf der linken Seite des Bilds zu erkennen, dass eine Vielzahl von QA-C zugehörigen Regeln aufgezeichnet sind. Insgesamt konnte man 6150 QA-C-Nachrichten und deren entsprechenden Eigenschaften zusammenfassen.

Folgende sind die Bewertungskriterien:
%
\begin{itemize}
\item \textbf{N:} New functionality has been introduced.
\item \textbf{F:} A fix of a bug or problem feature. 
\item \textbf{C:} A significant change has been implemented to existing behaviour.
\item \textbf{G/L/GL:} Messages realocated to a different message group or level.
\end{itemize}
%

In der V-Spalte der gezeigten Tabelle wird in Abhängigkeit der  modifizierten Versionen angegeben, ob die Eigenschaften der QA-C-Regel im Bezug auf die 7.0 Version gleich geblieben sind, sich geändert haben oder vielmehr neu dazu gekommen sind. Letzteres kann man sich am Beispiel der QA-C Nachricht 4303 dadurch klar machen, dass diese Nachricht erst in der Version 8.0 eingeführt worden ist. Ab dann hat sie bis einschließlich der Version 9.0 keine Änderung erfahren. Im Gegensatz dazu gibt es neben der Nachricht 4242 eine Vielzahl von QA-C-Nachrichten, die in der Version 8.1 neu eingeführt wurden und in den weiteren release notes Änderungen (z.B. gelöscht) erfahren haben. 

Letztere Zusammenhänge sind bei der Bewertung, inwiefern sich der erwähnte automatisierte Umstieg bei der MISRA-Prüfung ermöglichen lässt, von hoher Bedeutung. Man kann nämlich ausgehend von der Anzahl an veränderten bzw. neuen Nachrichten einschätzen, wie hoch der dabei erforderliche Aufwand ist.

\begin{longtable}{|l|l|}
\hline
\textbf{Eigenschaft der Regel} & \textbf{Anzahl an betroffenen Regeln} \\
\endhead
\hline
Gelöscht & 14 \\
\hline
neu eingeführt & 390\\
\hline
geändert(einschließlich C/F/G/L/GL) & 356\\
\hline
\caption{Relevante Zusammenhänge aus Menge der geprüften QA-C-Regeln.}
\label{tab:TabQAC7_9}
\end{longtable}

\tabvref{tab:TabQAC7_9} stellt wichtige Bewertungskriterien dar, um eine plausible Aussage über den angestrebten automatisierten Umstieg der betrachteten MISRA-Analysen geben zu können. 

In erster Linie sind im Laufe der Versionen eine hohe Anzahl an neuen geprüften QA-C-Nachrichten eingeführt worden. Auf der anderen Seite gibt es sehr viele Nachrichten, deren Struktur geändert oder angepasst worden sind. Wird ein Entwicklungsprojekt mit der Version 9.0 des QA-C-Analysetools geprüft, dann ist mit hoher Wahrscheinlichkeit zu erwarten, dass dabei eine hohe Anzahl an Warnungen angezeigt werden. Die entsprechenden Stellen im Code, auf welche sich die Warnungen beziehen, müssten nachträglich  dementsprechend händisch einzeln angepasst\footnote{Die entsprechenden \glqq deviations\grqq~im Code müssten durch plausiblen \glqq justifications\grqq~begründet werden.} werden.
\newpage
%
\section{Fünfte Woche}\label{sec:VierteWoche}
%
\subsection{Wochenübersicht}
%
Tabelle
%
\subsection{Arbeitsbericht}
%
Beim letzten Teil der ersten Aufgabestellung ginge es darum ein Projekt aufzustellen, um eine Vielzahl von Basissoftware-Modulen sowohl mit QA-C 7.0 als auch QA-C 9.0 zu analysieren. Ziel dieser Teilaufgabe ist es, eine Voruntersuchung zur Integration von QA-C9\footnote{QA-C9 weist auf die Version 9.0 des betrachteten Analysewerkzeugs hin} in die bestehende Entwicklungsinfrastruktur durchzuführen. Die im letzten Kapitel gezeigten Ergebnissen sollten soweit möglich dadurch betätigt werden.

Vor der Beschreibung der genannten QA-C-Analysen wird auf die Einstellungen eines QA-C9-Projekts eingegangen.
%
\paragraph*{Bestandteile und wichtige Einstellungen eines QA-C9-Projekts}
%
Erst dieses Jahr veröffentlichte QA-Systems die genannte QA-C9-Version. Aus diesem Grund konnte die Voruntersuchung nur mithilfe einer Testlizenz stattfinden.

Die Dokumentation, welche von QA-Systems zur Verfügung gestellt wird, sollte somit zur richtigen Verwendung des Tools genau analysiert. Dabei wurde festgestellt, dass im Vergleich zu den \textit{personality files}, die bei QA-C7 verwendet wurden, verwandte Files in QA-C9 erstellt werden, um ein Projekt einzustellen. 

Analog zum Unterkapitel \ref{QAC7Einf} werden im Folgenden die Einstellungsfiles eines QA-C9 Projekts zusammenfassend beschrieben:

\begin{itemize}\label{it:ConfFileQA9}
\item Analysis Configuration File (ACF): \\
definiert die Analyse-Einstellungen, die projektabhängig sind wie Include-Pfade, projektabhänigie Defines, usw.
\item  Rule Configuration File (RCF): \\
Einstellungen bezüglich der für die Untersuchung relevanten QA-C-Nachrichten.
\item Compiler Compatibility Templates (CCT): \\
definiert die Einstellungen für den Compiler, der bei der Entwicklung der Source Files verwendet wird. 
\item Project Definition File (prqaproject.xml): \\
Hierbei werden u.a. die Pfade der zu analysierenden Files angegeben.
\end{itemize}

Mit der QA-C9-Version ist es möglich ein Projekt über die vorhandene Benutzeroberfläche (siehe \figvref{fig:QAC9_GUI}) einzustellen oder ebenfalls dadurch, dass man die oben genannten Files entsprechend bearbeitet. 
%
\begin{figure}[!htp]
\centering
\includegraphics[scale=0.5]{./Bilder/QAC9_GUI.pdf}
\caption{Benutzeroberfläche der QAC9-Software.}
\label{fig:QAC9_GUI}
\end{figure}
%
\paragraph*{Ergebnisse einer statischen Analyse mithilfe von QA-C9}
%
Um sich mit QA-C9 vertraut zu machen, lohnt es sich, mit dem Aufstellen eines Analyseprojekts für die bereits im Unterkapitel \ref{QAC7Einf} behandelte Simplecomponent klein anzufangen.

Nachdem das QA-C9-Projekt über die GUI eingestellt wurde, war es möglich entsprechende Reports zu erstellen. Die Reports können als HTML-Files oder direkt aus bestimmten Stellen in der GUI abgelesen werden.

Die Ergebnisse der Analyse mit der Version 7.0 wurden zusammen mit den oben genannten Ergebnissen der Reports dazu verwendet, um die Tabelle zu erstellen, die in \figvref{fig:QACSimpleComp} dargestellt wird.

Auf der linken Seite der Abbildung sind die analysierten Files dargestellt. Die Ergebnisse sind nach den verwendeten Versionen sortiert. Eine solche Darstellung kann hilfreich sein, um beipielsweise Nachrichten aufzuzeichnen, die bei einem bestimmten analysierten File in einer Version jedoch nicht in der anderen erkannt werden. Das ist der Fall beispielsweise bei der Nachricht 841, die in allen Files bei der Version 7.0 jedoch in keiner der folgenden Versionen erkannt wird. 
%
\begin{figure}[!ht]
\centering
\includegraphics[scale=0.7]{./Bilder/QACSimpleComp.pdf}
\caption{Benutzeroberfläche der QAC9-Software.}
\label{fig:QACSimpleComp}
\end{figure}
%

Drauf aufbauend sollte ein umfangreicheres QA-C9-Projekt zur statischen Codeanalyse einer relativ größeren Anzahl an BSW-Modulen eingestellt werden. In diesem Fall würde sich die Einstellung eines solchen Projekts als sehr umständlich erweisen. Dies liegt daran, dass die Quelldateien sich normalerweise in mehreren Unterordner organisiert befinden und die jeweiligen Pfade angegeben werden müssen. Letzteres betrifft sowohl die Eingabe der Einstellungsfiles über die GUI als auch die manuelle Bearbeitung der Einstellungsfiles ACF, RCF, CCT sowie der XML-Project-Definition-Datei. 

Bei so einer großen Anzahl an zu analysierenden Files, die in der Regel sehr oft bei einem Entwicklungsprojekt vorkommen, sollte trotzdem eine automatisierte Generierung von Analysereports möglich sein. Hierbei schafft die Verwendung einer Skriptsprache wie PERL oder Phyton Abhilfe. Letztere erleichtern u.a. den automatisierten Umgang mit Textdateien und Verzeichnissen.

Die durchgeführte Analyse erwies sich als umständlich und erforderte starke Konzentration, um aus den genannten Dokumenten die benötigten Informationen herauszufinden. 

Da bisher in der Abteilung einige Mitarbeiter bei der Programmierung mit PERL große Erfahrung gesammelt haben, entschloss ich mich diese Programmiersprache zur Bearbeitung der Konfigurationsdateien einzusetzen. Eine geeignete IDE, mit der es möglich ist, PERL-Skripte zu erstellen, kompilieren und Debuggen ist nicht leicht zu finden. Eine gute alternative bietet die als Eclipse-Plugin kostenlos zur Verfügung stehende EPIC-IDE. Diese stellt nicht nur die Möglichkeit dar, PERL-Skripte zu bearbeiten, sondern auch diese zu kompilieren und zu debuggen.

In \figvref{fig:EPICskr1} werden sowohl ein kleiner Teil des ersten erstellten PERL-Skripts als auch die genannte EPIC-IDE gezeigt.

Bei dieser Aufgabe  Mithilfe des erstellten Skripts war es möglich, die oben beschriebene Aufgabe zu lösen. Der vollständige Skript befindet sich in \lstref{lst:PERL_Dateiueb}.

%
\begin{figure}[!htp]
\centering
\includegraphics[scale=0.55]{./Bilder/EPIC_skr1.pdf}
\caption{EPICskr1}
\label{fig:EPICskr1}
\end{figure}

Die Übertragung der Dateien war nicht die einzige Aufgabe, die zum Erstellen des QA-C9-Projektes durchgeführt werden musste. Es war außerdem notwendig die Pfade der einzelnen zu analysierenden Dateien anzugeben. Wie weiter oben in diesem Kapitel erläutert, bedient sich QA-C9 einer XML-Konfigurationsdatei, um dabei sowohl die Pfade der zu analysierenden Dateien als auch weitere wichtige Einstellungen zu entnehmen.

Diese XML-Datei als Textdatei so zu behandeln, dass dabei die richtige Einträge hinzugefügt werden, ist sehr hilfreich, um eine automatisierte statische Codeanalyse von sehr vielen Sourcefiles durchzuführen. Dazu wird ein von QA-Systems zur Verfügung gestellte Compiler (QA-CLI) mit den richtigen Optionen aufgerufen, wobei dem Compiler auch die richtigen QA-C9-Konfigurationsdateien zur Verfügung stehen müssen. Diese Methode hat man zwar bisher in der Abteilung eingesetzt, der dabei verwendeter Compiler gehört zu der QA-C7-Version \cite{MISRACodeMetric}.

Eine genaue Beschreibung der Kompilerbefehle (QA-CLI) bezüglich der QA-C9-Version können in \cite{PRQA9}~nachgelesen werden.

Mit dem Ziel ein QA-C-Projekt automatisiert über den genannten Compiler auszuführen, habe ich ebenfalls einen PERL-Skript programmiert. Dieser bearbeitet einen vorhandenen Template-File eines QA-C9-Projekts, welches nur wenige Einträge enthält und fügt die relevanten, zu analysierende Files und deren Pfadenamen hinzu. Das Ergebnis nach der Ausführung des in \lstref{lst:PERL_XML} angegebenen PERL-Skripts kann im folgenden Listing betrachtet werden:
%
\definecolor{forestgreen}{RGB}{34,139,34}%definition fuer xml Comment style 

\begin{lstlisting}[language=XML, caption = {Compiler personality file QA-C.p\_c}, label={lst:QAC9_xml}]
...
  <language target="C++">
   <extension ext=".cxx"/>
  </language>
  <language target="C++">
   <extension ext=".cc"/>
  </language>
  <language target="C++">
   <extension ext=".CPP"/>
  </language>
  <language target="C++">
   <extension ext=".CXX"/>
  </language>
  <language target="C++">
   <extension ext=".CC"/>
  </language>
 </file_extensions>
 <!-- Files in project... -->
 <files>
  <!-- Explicit files... -->
  <file target="C" name="Adc.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="BswM.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="Can.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="Can_Irq.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="CanIf.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="CanNm.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="CanSM.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="CanTp.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="CanTrcv_30_GenericCan.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="CanTSyn.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="CanXcp.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="Com.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="ComM.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="Crc.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="Cry.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="Cry_AesDecrypt128.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="Cry_AesEncrypt128.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="Cry_Fips186.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="Cry_HmacSha1.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="Cry_RsaDecrypt1024.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="Cry_RsaSha1SigVer.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="Csm.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="Dbg.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="Dcm.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="Dcm_Ext.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="Dem.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="Det.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="Dio.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="Dlt.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="DoIP.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="E2E.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="E2E_P01.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="E2E_P02.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="E2E_P04.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
  <file target="C" name="E2E_P05.c" folder="=Z:/PES/PES1/res/Task01/QAC_Analysen/Relevant"/>
...
\end{lstlisting}
%
\newpage
\section{Sechste Woche}
%
\subsection{Wochenübersicht}
%
Tabelle
%
\subsection{Arbeitsbericht}
%
In der sechsten Woche wurde mir die 2. Aufgabestellung vorgestellt. Dabei ginge es darum, mich umfassend mit einem Basic Test Environment (BTE) zu beschäftigen, welches in der PES Abteilung entwickelt wurde. Ich musste mich mit dem Tool vertraut machen und seine Funktionsweise verstehen, um es anschliessend um weitere Funtionalitäten zu erweitern.
%
\subsubsection{Zweite Aufgabenstellung}
% 
Wie oben erwähnt war es notwendig die Tool-Eigenschaften und seine Besonderheiten zusammenzufassen und zu kennen. Anhand dieser Analyse wird es klarer, an welcher Stelle die BTE-Funktionalitäten zu ergänzen sind.
%
\subsubsection*{BTE - Basic Test Environment}
%
Das Basic Test Environment (BTE) ist ein in \verb|C| implementiertes Component-Unit-Test-Framework, mit dessen Hilfe man in der Abteilung hardwareunabhängige (AUTOSAR-) BSW-Komponeneten testet \cite{BTE}.

Die in \figvref{fig:BTE_func1} vorgestellte BTE-Version bietet verschiedene Testsfunktionalitäten, u.a. das Nachbilden (emulation) einer inneren ECU-Umgebung, die Ereignisprotokollierung und das Erstellen von entsprechenden Reports \cite{BTE}. 
%
\begin{figure}[!htp]
\centering
\includegraphics[scale=0.8]{./Bilder/BTE_func1.pdf}
\caption{Framework-Emulation of ECU environment on a PC. Entnommen aus \cite{BTE}.}
\label{fig:BTE_func1}
\end{figure}
%

Im Diagram wird durch die rote Box die Nachbildung der inneren ECU-Umgebung gezeigt. Diese Box besteht aus mehreren Platzhaltern, sogenannten Stubs, die Komponenten simulieren/ersetzen. Dabei ist ersichtlich, dass der Testplan sowohl die simulierten Stubs als auch die Component-Under-Test (CUT) steuert, damit vom Framework einen entsprechenden Log/Report ausgegeben wird.

Das Klassendiagram, welches in Abbildung \ref{fig:BTELogListold} gezeigt wird, gibt einen Teil der BTE-Struktur wieder. Dabei befinden sich diejenige Komponenten, welche sich um die Erstellung eines Testreports kümmern. Das Teilmodul \verb+TestHandler+ steuert den Ablauf der Testdurchführung, wobei nur über das Modul \verb+ReportHandler+ auf die Testreport-Datei zugegriffen wird, um diese zu bearbeiten. Die Funktionalitäten \verb+X+ und\verb+Y+ bezeichnen bestimmmte Komponenten der BTE, die wie der \verb+ReportHandler+ direkt auf die den VTR-Report zugreifen bzw. ihn bearbeiten können. Im Gegensatz dazu existieren weitere Funktionalitäten wie \verb+BTE Functionality_Z+, die den Testreport nicht bearbeiten können, sondern andere Services zur Verfügung stellen.
%
\begin{figure}[!htp]
\centering
\includegraphics[scale=0.75]{./Bilder/BTELogListold_cropped.pdf}
\caption{BTEUseCase}
\label{fig:BTELogListold}
\end{figure}
%

Gegenüber den genannten Funktionalitäten gibt es bei der Verwendung des BTEs folgenden Nachteil, der sich eher als eine Einschränkung äußert: Mit dem Tool lassen sich bequem Testreports auf einem lokalen Rechner ausgeben und abspeichern. Dabei werden jedoch betriebssystemabhängige Funktionen zum Umgang mit Strings benötigt, die in der Regel viele Hardwareresourcen verbrauchen. Die BTE lässt sich somit nur auf Rechnern sinnvoll einsetzen, die einen hohen Arbeitsspeicher und genug Speicherplatz zur Verfügung stellen.

\begin{Aufgabenstellung}
Die Aufgabestellung basiert auf folgender Anforderung: Es wäre auch vorteilhalft, die BTE-Struktur so zu erweitern, dass das Tool ebenfalls auf einem eingebetteten System läuft. Der Grund dafür ist, dass es dadurch möglich wäre, entsprechende Testreports unter realen Bedingungen erstellen zu können. 
\end{Aufgabenstellung}

%
\subsubsection*{Test-Hardware}
%
Eine Test-Hardware, auf der die BTE laufen soll, wurde mir zur Verfügung gestellt. Es handelte sich dabei um das STM32F4-DiscoveryBoard, auf dem der  Mikrocontroller STM32F407VG (Cortex-M4-Hardwarearchitektur) eingebaut ist.

Um die Aufgabe zu lösen, war es notwendig das STM32F4-DiscoveryBoard in Betrieb zu nehmen und dabei eine passende Entwicklungsumgebung zu verwenden. Diese sollte dementsprechend geignete Compiler- und Linker-Bibliotheken zur Verfügung stellen, die das Erstellen einer Applikation für den  Mikrocontroller unterstützen. 
%
\begin{figure}[!htp]
\centering
\includegraphics[scale=0.4,angle=90]{./Bilder/stm32f4_discovery.jpg}
\caption{Verwendete Test-Hardware (STM32F4), auf welcher die RT-BTE lauffähig sein soll.}
\label{fig:discovery}
\end{figure}
%

Da ich in vergangenen Projekten bereits Erfahrung bei der Programmierung des genannten Mikrocontrollers sammeln konnte, entschloss ich mich die Eclipse-IDE und das dabei zur Verfügung stehende CDT\footnote{C/C++ Development Tooling}-Plugin einzusetzen. Dieses erweitert Eclipse und bietet u.a. die Möglichkeit C/C++ Programme zu editieren, zu kompilieren und zu linken~\cite{EclipseCDT}. 

In ~\cite{EclipseSTM32Youtube} werden weitere, notwendige Tools angegeben, die die Programmierung des Mikrocontrollers ermöglichen:
%
\begin{itemize}
\item GDB Hardware Debugging: ein zusätzliches Eclipse-Plugin
\item GDB: der GNU Debugger-Programm
\item GDB-Server: stellt eine Verbindung mit GDB und dem JTAG-Interface her.
\item Toolchain: make, Compiler, Linker, GDB, Bibliotheken, usw.
\end{itemize}
%
\newpage
%
\section{Siebte Woche}\label{siebteWoche}
%
\subsection{Wochenübersicht}
%
Tabelle
%
\subsection{Arbeitsbericht}
%
\subsubsection{Durchführung der zweiten Aufgabenstellung}\label{durchfAuf2}
%
Jedes Software-Projekt basiert auf einer grundlegenden Anforderungsanalyse. Bei der vorliegenden Aufgabe wurde ebenfalls eine durchgeführt, die im folgenden vorgestellt wird.
%
\subsubsection*{Anforderungsanalyse}\label{Anforderungen}
%
Die Erweiterung des BTE-Tools soll folgende Anforderungen erfüllen:
%
\begin{enumerate}
\item Ursprüngliche Implementierungen der BTE-Funktionalitäten, sollen durch Erweiterungen möglichst wenig modifiziert werden.
\item Es soll auf einem Embedded-Prozessor lauffähig sein und mit vorhandenen Hardware-Ressourcen möglichst sparsam umgehen.
\item Die ursprüngliche BTE-Funktionalitäten, einen Test einer Software-Komponente auf einem lokalen Rechner durchzuführen und dabei einen passenden Report zu erstellen, sollen immerhin vorhanden sein.
\item Ein Testreport soll bei Verwendung der BTE auf einem eingebetteten System durch eine entsprechende Kodierung auf der RAM des betrachteten Systems abgespeichert werden können.
\item Eine Funktionalität soll vorhanden sein, um aus einer vorgegebenen Binärdatei, wo der RAM-Speicherbereich bzw. der binär kodierte Testreport sich befindet, einen Testreport erstellen zu können.
\item Der aus der Binärdatei erstellte Testreport soll soweit wie möglich dieselbe Struktur haben, wie ein Testreport, der über die BTE auf einem lokalen Arbeitsrechner erstellt wird.
\end{enumerate}
%
In \figvref{fig:BTEUseCase} wird ein Anwendungsfalldiagramm gezeigt, um die funktionalen Anforderungen an dem vorliegenden System besser zu verstehen. 

Dabei ist ersichtlich, dass allein der Anwendungsfall \textsf{\textbf{excecute test on embedded device}} die ursprüngliche BTE-Funktionalitäten erweitert. Der Anwender hat deshalb dadurch die Möglichkeit, über das erweiterte Tool Tests sowohl auf einem lokalen Arbeitsrechner als auch auf einem eingebettenen Prozessor durchzuführen. Ein Report kann ebenfalls mithilfe des erweiterten Tools erstellt werden. Im gezeigten Anwendungsfalldiagram ist somit nicht relevant, über welchen Weg der entsprechende Testreport erzeugt wird.

Eine genaue Beschreibung der Umsetzung des genannten Anwendungsfall ist weiter unten in Abbildung \ref{fig:BTELogList} als Klassendiagramm zu sehen.
%
\begin{figure}[!htp]
\centering
\includegraphics[scale=0.9]{./Bilder/BTEUseCase.pdf}
\caption{BTEUseCase}
\label{fig:BTEUseCase}
\end{figure}%
%

\subsubsection*{Verwendeter Lösungsansatz}\label{Ansaetze}
%
Man muss mit den vorhandenen Hardwareressourcen des eingebetteten Systems, wo die BTE eingebunden werden soll, sparsam umgehen und dabei auch eine Methode einsetzen, bei der beispielsweise der Test-Report direkt auf dem beschränkten RAM-Speicher abgelegt wird. Dazu ist es notwendig, eine bestimmte Codierung festzulegen, wie die Daten abzuspeichern sind.

Am Ende der Testdurchführung soll der Test-Report wieder als eine XML-Datei vorliegen. Dies ist nur dann möglich, wenn die entsprechenden Stellen des RAM-Speichers aus dem eingebetteten System extrahiert und anschließend analysiert werden. Dieser RAM-Bereich, welcher als eine Binärdatei vorliegt, würde sich mithilfe einer Anwendung analysieren lassen. Diese Anwendung wird in einer ausgewählten Skriptsprache programmiert und implementiert die Dekodierung der Daten so, dass ein Test-Report erneut als eine XML-Datei erstellt werden kann.

Zwei Mögichkeiten können betrachtet werden, um mit den knappen Softwareressourcen der Embedded Platform umzugehen:

\begin{enumerate}
\item Man bindet entsprechende Ersatzbibliotheken ein, die optimiert und Hardwareressouercen-sparend arbeiten.
\item Man bietet dem Anwender die Möglichkeit an, durch entsprechende Präprozessor-Direktiven diejenigen Teile vom vorhandenen BTE-Code beim Kompiliervorgang auszublenden, die viele Hardware-Ressourcen benötigen.
\end{enumerate}

Aus zeitlichen Gründen kann keine eigene Bibliothek erstellt werden, um den ersten Lösungsansatz umzusetzen. Die zweite Möglichkeit wird deshalb zur Lösung der Aufgabe gewählt. Dabei wird wie folgt vorgegangen:

Mit vorhandenen und zusätzlich eingeführten Präprozessor-Direktiven (\verb+#define+) wird die Möglichkeit geboten, die BTE-Methodensaufrufe auszublenden, die zu viele Rechenressourcen benötigen. Ebenfalls sollten solche Methodensaufrufe ausfallen, die von der eingebetteten Hardware nicht unterstützt werden. Ein Beispiel dazu sind solche Methoden, die das lokale Abspeichern von Dateien ermöglichen wie fopen, fclose, sprintf, usw. 

\begin{description}
	\item[\textbf{\texttt{\#define USE\_PRINTF}}]: Mithilfe dieser neu eingeführten Direktive wird der 2. Anforderung Rechnung getragen (siehe \secref{Anforderungen}). Dabei sollen bei Abwesenheit dieser Direktive alle Codeabschnitte ausgeblendet werden, bei denen Strings und deren Verarbeitung vorkommen. Diese können nur dann eingesetzt werden, wenn die Hardware genug RAM zur Verfügung stellt und die Methoden implementiert sind. Siehe dazu den folgenden Codeabschnitt.
%
\begin{lstlisting}[style=C_colored_smallfont, caption = {Ausschnitt aus BteTestHandler.c}, label={lst:useprintf1}]
...
typedef struct stBteTestSequence
{
  uint16 id_num;
  uint8 isOpen;
#if defined ( USE_PRINTF )
  char  description_id[50];
  char  description_name[100];
  char  description_parameter[100];
  char  description_purpose[100];
  char  description_reference[100];
  char  description_text[1000];
#endif
} tBteTestSequence;
...
\end{lstlisting}
%
\begin{lstlisting}[style=C_colored_smallfont, caption = {Ausschnitt aus BteCheck.c}, label={lst:useprintf1}]
...
void BteAvailableOk( char *text )
{
#if defined USE_PRINTF
  char output[kBteTextSize];
  sprintf( output, "%s is available (as expected)", text );
  BteOk( output );
#else
  BteOk( text );
#endif

}
...
\end{lstlisting}
%
\item[\textbf{\texttt{\#define USE\_INTERNAL\_LOG}}]: Mithilfe dieser neu eingeführten Direktive wird den Anforderung 1, 2, 3 und 4 Rechnung getragen (siehe \secref{Anforderungen}). Dabei werden diejenigen Stellen vom Code eingeblendet, wo die von mir implementierten Module vorkommen. Unter anderem wird dabei die Funktionalität eingeschaltet, den Testreport in den RAM-Speicher abzulegen, wie im folgenden Codeabschnitt zu sehen. 
%
\begin{lstlisting}[style=C_colored_smallfont, caption = {Ausschnitt aus TscTest.c}, label={lst:useinternal}]
...
#if defined (USE_INTERNAL_LOG)
  BteTestSequence_BeginID(6); // Der Anwender soll diese Methode verwenden
#else
  BteTestSequence_Begin("[TSEQ_Mip_GetVersionInfo.001]");
#endif
...
\end{lstlisting}
%
\begin{lstlisting}[style=C_colored_smallfont, caption = {Ausschnitt aus BteLog.c}, label={lst:useinternal}]
...
#if defined USE_INTERNAL_LOG
    // Event entry in the internal array list
    BteLogList_AddEvent( pEvent );
#endif
...
\end{lstlisting}
%
\item[\textbf{\texttt{\#define USE\_HARDWARE}}]: Diese Präprozessor-Direktive wurde ebenfalls eingeführt, um den Anforderungen 1 und 2 Rechnung zu tragen (siehe \secref{Anforderungen}). Bestimmte Codeabschnitte werden dabei eingeblendet, wenn die BTE in einem eingebetteten System verwendet wird. Dadurch werden die hardwareabhängige bzw. ECU-eigene Funktionsaufrufe eingeblendet. Siehe dazu folgenden Codeabschnitt.
%
\begin{lstlisting}[style=C_colored_smallfont, caption = {Ausschnitt aus TscTest.c}, label={lst:usehardware}]
...
/* Hardware Includes */
#if defined ( USE_HARDWARE )
#include "stm32f4xx_hal.h"
#include "stm32f4_discovery.h"
#endif
...
#if defined ( USE_HARDWARE )
  ConfigSTM32F4();
#endif
...
#if defined (USE_HARDWARE)
  /* Infinite loop */
  while (1)
  {
    BSP_LED_Toggle(LED4);
    HAL_Delay(1000);
 }
#endif
...
\end{lstlisting}
%
	\item[\textbf{\texttt{\#define BTE\_ENABLE\_TESTREPORT}}]: Durch das Umdefinieren dieser schon vorhandenen Direktive wird ein Ausblenden derjenigen Methodensaufrufe möglich, die mit dem Erstellen, der Bearbeitung und lokalen Abspeicherung von Dateiobjekten umgehen. Dadurch kann den Anforderungen 1, 2 und 3 Rechnung getragen werden (siehe \secref{Anforderungen}). Siehe dazu den folgenden Codeabschnitt.

\begin{lstlisting}[style=C_colored_smallfont, caption = {Ausschnitt aus BteLog.c}, label={lst:usetestrep1}]
...
#if defined (BTE_ENABLE_TESTREPORT)
    uint8 tempText[150];
    sprintf(tempText,"%s %s",pEvent->text_name,pEvent->text_param);
    if( pEvent->type == kBteEventType_Command )
    {
      BteReport_WriteElement( "cmd", pEvent->time, tempText );
    }
    else if ( pEvent->type == kBteEventType_Error )
    {
      BteReport_WriteElement( "fail", pEvent->time, tempText );
    }
    else
    {
      BteReport_WriteElement( "", pEvent->time, tempText );
    }
    BteTraceReport_WriteElement( pEvent );
#endif
...
\end{lstlisting}	
%
\begin{lstlisting}[style=C_colored_smallfont, caption = {Ausschnitt aus BteReport.c}, label={lst:usetestrep2}]
...
void BteReport_Write( char *text )
{
#if defined ( BTE_ENABLE_TESTREPORT )
  if( pBteTestReport != 0 ) 
  {
    fprintf( pBteTestReport, "%s\n",text );
  }
#endif
}
...
\end{lstlisting}
%
\end{description}
%
\newpage
\section{Achte Woche}
%
\subsection{Wochenübersicht}
%
Tabelle
%
\subsection{Arbeitsbericht}
%
%
Bei jeder Testdurchführung können je nach Voreinstellung die Ergebnisse der Methodensaufrufe in Form eines XML-Reports ausgegeben werden, was in Abbildung \ref{fig:ReportXML} gezeigt wird. Nach jedem dieser Methodensaufrufe besteht die Möglichkeit, die dabei übergebenen Parameter auch im Testreport auszugeben. Deshalb werden diese Parameter bei jedem Methodensaufruf vom BTE-Tool ebenfalls gelagert und anschliessend im Report ausgegeben. Dadurch ist es im Report ersichtlich, dass bei einer bestimmten Konstellation von Übergabeparametern der Methodensaufruf nicht gelungen ist.  
%
\begin{figure}[!htp]
\centering
\includegraphics[scale=0.4]{./Bilder/ReportXML.pdf}
\caption{BTEUseCase}
\label{fig:ReportXML}
\end{figure}
%

Zur Implementierung der Speicherung des Testreports auf dem RAM werden zwei unterschiedliche Ansätze berücksichtigt. Der der erste Ansatz weist bestimmte Nachteile auf, deshalb wird auf diese nur kurz eingegangen. Die zweite Möglichkeit wird dahingegen ausführlicher behandelt, denn auf ihr basieren die Lösungsergebnisse der vorliegenden Aufgabe. 

Bei jedem der erwähnten Lösungsansätze ist eine geignete Kodierung der Daten in Form eines geigneten Protokolls notwendig, welches die Datenspeicherung auf der RAM verwaltet.
%
\textbf{Report in Form einer Struktur (\texttt{stBteLogList}}):  

Der erste Ansatz, die Liste anhand einer Struktur abzuspeichern, wird durch \lstref{lst:structList} beschrieben. Dabei ist ersichtlich, dass der Datentyp \texttt{stBteLogList} aus einem 16-bit langen Eintrag (\textit{size}) und einer weiteren Struktur vom Typ \text{stBteEventLog} besteht. Letztere enthält zwei weitere Datentypen (\textit{code} und \textit{data}). 
%
\begin{lstlisting}[style=C_colored_smallfont, caption = {Ausschnitt aus TscTest.c}, label={lst:structList}]
typedef struct stBteEventLog 
{
  uint16 code;
  uint32 data;
} tBteEventLog;

typedef struct stBteLogList 
{
  uint16     size;
  tBteEventLog   elem[kBteLogList_size];
} tBteLogList;
\end{lstlisting}
%

Der Testreport wird auf Basis dieser beiden Strukturen im RAM des eingebetteten Prozessors abgelegt. Diese Struktur muss unterschiedliche Kennungen enthalten, welche zusammen das genannte Protokoll definieren. Damit ist eine hierachiche Trennung der gespeicherten Daten und deren Unterscheidung gewährleistet. Tabelle \ref{tab:Protokoll1} zeigt die Auswahl der verwendeten Kennungen.
%
%\begin{longtable}{|l|l|}
%\hline
%\textbf{Kennung} & \textbf{Beschreibung} \\
%\endhead
%\hline
%0xFF & Kennung eines Testcases\\
%\hline
%0x21 & Kennung für 1. Datenelement\\
%\hline
%0x22 & Kennung für 2. Datenelement\\
%\hline
%0x23 & Kennung für 3. Datenelement\\
%\hline
%0x24 & Kennung für 4. Datenelement\\
%\hline
%0x25 & Kennung für 5. Datenelement\\
%\hline
%0x5C & Kennung für \textit{End of file}\\
%\hline
%0x6E & Kennung für \textit{End of file}\\
%\hline
%\caption{Relevante Zusammenhänge aus Menge der geprüften QA-C-Regeln.}
%\label{tab:Protokoll1}
%\end{longtable}
%
%
\begin{table}[ht]
\caption{Nonlinear Model Results}
% title of Table
\centering 
% used for centering table
\begin{tabular}{c c c c}
% centered columns (4 columns)
\hline
\hline                        %inserts double horizontal lines
Case & Method \#1 & Method \#2 & Method \#3 \\ [0.5ex]% inserts table 
%heading
\hline
                  % inserts single horizontal line
1 & 50 & 837 & 970  \\
% inserting body of the table
2 & 47 & 877 & 230  \\
3 & 31 & 25  & 415  \\
4 & 35 & 144 & 2356 \\
5 & 45 & 300 & 556 \\ [1ex]      % [1ex] adds vertical space
\hline
%inserts single line
\end{tabular}
\label{table:nonlin}
% is used to refer this table in the text
\end{table}
%

Wird ein neuer Testreport erstellt, dann wird am Anfang die Länge(\textit{size}) von \texttt{tBteLogList} auf Null gesetzt. Dadurch werden alle alten Einträge der Liste überschrieben und gelöscht. Im nächsten Schritt werden in Abhängigkeit der vorgegebenen Testcases die definierten Kennungen innerhalb der vorhandenen Elementen der Liste \texttt{elem} abgespeichert. 

Abbildung \ref{fig:Protocol1} zeigt beispielshaft, wie das Protokoll zur Abspeicherung des Testreports auf der RAM umgesetzt wird. 
%
\begin{figure}[!htp]
\centering
\includegraphics[scale=0.9]{./Bilder/Protocol1.pdf}
\caption{BTEUseCase}
\label{fig:Protocol1}
\end{figure}
%

Nachteilig bei dieser Art der Abspeicherung ist, dass der Compiler die größe des Bereiches so groß wie die größte in der Liste vorkommende Variable festlegt. Dabei wird somit jede Variable als eine 32-Bit große Variable behandelt, was im Falle eines 8-bit großen Eintrags zu Speicherplatz-Verschwendung führt. Damit der Compiler diese Optimierungen nicht selbst vornimmt, muss man weitere Einstellungen bei den Compiler-Optionen durchführen, was aber noch mehr Zeit in Anspruch nimmt.
%
\newpage
%
\section{Neunte Woche}
%
\subsection{Wochenübersicht}
%
Tabelle
%
\subsection{Arbeitsbericht}
%
Während dieser Woche galt meine Arbeit weiterhin der Lösung der 2. Aufgabe. 

\textbf{Report in Form eines Byte-Arrays \texttt{BteLogArray}}: 

Report wird in Form eines normalen Arrays vom Typ \verb|uint8| im RAM des betrachteten Prozessors abgespeichert. 
Die verarbeiteten Informationen bei den Methodensaufrufen werden ebenfalls sequenziell innerhalb des Arrays abgelegt. Dabei richtet sich die Abspeicherung nach dem folgenden, vordefinierten Protokoll:
%
%\begin{longtable}{|l|l|}
%\hline
%\textbf{Kennung} & Beschreibung \\
%\endhead
%\hline
%0xFF & Kennung eines Testcases\\
%\hline
%0x5C & Kennung für End of file\\
%\hline
%0x6E & Kennung für End of file\\
%\hline
%\caption{Relevante Zusammenhänge aus Menge der geprüften QA-C-Regeln.}
%\label{tab:Protokoll1}
%\end{longtable}
%

%
\begin{table}[ht]
\caption{Nonlinear Model Results}
% title of Table
\centering 
% used for centering table
\begin{tabular}{c c c c}
% centered columns (4 columns)
\hline
\hline                        %inserts double horizontal lines
Case & Method \#1 & Method \#2 & Method \#3 \\ [0.5ex]% inserts table 
%heading
\hline
                  % inserts single horizontal line
1 & 50 & 837 & 970  \\
% inserting body of the table
2 & 47 & 877 & 230  \\
3 & 31 & 25  & 415  \\
4 & 35 & 144 & 2356 \\
5 & 45 & 300 & 556 \\ [1ex]      % [1ex] adds vertical space
\hline
%inserts single line
\end{tabular}
\label{table:nonlin}
% is used to refer this table in the text
\end{table}
%


Wie man merkt, ist bei dieser Art der Datenspeicherung nicht notwendig, weitere Kennungen einzuführen als den Anfang eines neuen Testcases und das Ende des gesammten Testreports. Der Grund dafür ist, dass über die Angabe der Anzahl der an die Funktion übergebenen Parameter direkt festgelegt wird\footnote{Dies geschieht beim Dekodieren des Testreports anhand des PERL-Skripts, dessen Umsetzung noch beschrieben wird.}, festgelegt wird, wie viele relevanten Daten in den Testreport abzuspeichern sind.

Da in der Regel die übergebenen Parameter und manche Daten, die auf dem Testreport vorkommen müssen, nicht unbedingt vom Typ \texttt{uint8} sind sondern größer (\texttt{uint16} bzw. \texttt{uint32}), kann deren Inhalt nicht direkt in die einzelnen Einträge des Byte-Arrays passen. Vor der Abspeicherung müssen diese Informationen deshalb so zerlegt und angepasst werden, dass sie immer in den 8-Bit großen Einträgen des genannten Arrays hinein passen. 

Diese Datenanpassung wird mithilfe der in \lstref{lst:ArrayList} gezeigten Methoden durchgeführt. Dabei werden die benötigten Daten nicht nur zerlegt, sondern auch direkt in dem Array gespeichert. 

\begin{lstlisting}[style=C_colored_smallfont, caption = {Ausschnitt aus TscTest.c}, label={lst:ArrayList}]

void BteLogList_Serialize32(uint32 data)
{
  BteLogArray[kBteLogArray_position++] = (uint8)(data>>24);
  BteLogArray[kBteLogArray_position++] = (uint8)((data>>16) & 0xFF);
  BteLogArray[kBteLogArray_position++] = (uint8)((data>>8) & 0xFF);
  BteLogArray[kBteLogArray_position++] = (uint8)(data & 0xFF);
}

void BteLogList_Serialize16(uint16 data)
{
  BteLogArray[kBteLogArray_position++] = (uint8)((data>>8) & 0xFF);
  BteLogArray[kBteLogArray_position++] = (uint8)(data & 0xFF);
}
\end{lstlisting}

In Abbildung \ref{fig:Protocol2} ist gezeigt, wie die Daten im \verb|BteLogArray| abgespeichert werden und das Protokoll dazu definiert ist. Dabei ist bei den Stellen zu erkennen, wo die Variablen \verb|testcaseID| und \verb|time| gespeichert sind, wie das Program die Daten in kleineren 8-bit große Datenfelder zerlegt. Dabei wird beispielsweise die in \lstref{lst:ArrayList} gezeigte Funktion \verb|BteLogList_Serialize32| verwendet, um die 32-bit große Variable \verb|time| zu zerlegen.

Auf diese Art und Weise wird der Anforderung, mit Hardwareressourcen möglichst sparsam umzugehen, ebenfalls Rechnung getragen. Jedes Feld des Arrays ist nämlich mit relevanten Daten vom Testreport befüllt.

Eine beispielshafte 
%
\begin{figure}[!htp]
\centering
\includegraphics[scale=0.9]{./Bilder/Protocol2.pdf}
\caption{BTEUseCase}
\label{fig:Protocol2}
\end{figure}
%
\begin{landscape}
\begin{figure}[!htp]
\centering
\includegraphics[scale=0.8]{./Bilder/BTELogList_cropped.pdf}
\caption{BTEUseCase}
\label{fig:BTELogList1}
\end{figure}
\end{landscape}
%
XXX Bild zur Architektur des Reports, welches auf der RAM gespeichert wird. 

Die Stellen vom Speicher, wo die zu interessierenden Daten der durchgeführten Tests zum Erstellen eines Reports abgelegt wurden, lassen sich mit Hilfe eines memory mapping des entsprechenden Prozessors analysieren. Dies ist mit einem Debugger möglich und kann bestenfalls als binary file ausgegeben werden. Das ist die Beschreibung des Ansatzs, welcher von Markus und Timo erklärt worden ist.

Ein Ansatz, um aus den binary files ein Report zu erstellen, ist, das binary File mit Hilfe einer Skriptsprache zu analysieren, damit das ursprungliche von der BTE auf dem PC erzeugte Report erneut ausgegeben werden kann. Die genaue Darstellung des Perl-Scripts (Perl-Listing) kann im Anhang \ref{cha:tools} gefunden werden. 

Die erzielten Lerneffekte sind vor allem der Umgang mit einer Skriptsprache, das Speicherplatz sparend Codieren in C.
%
\section{Zehnte Woche}
%
\subsection{Wochenübersicht}
%
Tabelle
%
\subsection{Arbeitsbericht}
%
Da die Reports auf einer beliebigen Hardware zu implementieren sind, sollte eine bestimmte Hardware ausgesucht werden. Die Hardware die mir vorgestellt wurde, war das STM32F4-Entwicklungsboard. Mit dieser Hardware habe ich in der Vergangenheit schon zu tun gehabt, deswegen konnte ich ohne große Mühe die Einstellungen vornehmen, um ein Projekt zu starten.

Das genannte Board lässt sich über ST-Link-Treiber flaschen , welcher vom Hersteller zur Verfügung gestellt wird.
%
\begin{landscape}
\begin{figure}[!htp]
%\fbox{\begin{minipage}{21.8cm}% 
\centering
\includegraphics[scale=0.5]{./Bilder/eclipsegit.pdf}
%\end{minipage}}%
\caption{eclipsegit}
\label{fig:eclipsegit}
\end{figure}
\end{landscape}
%
Der auf dem Mikrocontroller erzeugte Report sollte auf einer Speicher sparenden Art und Weise erstellt werden. Man hat sich 2 Möglichkeiten überlegt, wie dies geschehen soll. Letzteres wird im Folgenden Bild wiedergeben:

%Bild hier angeben%

Zu der Erkenntnis konnte man gelagen, dass die zweite Möglichkeit besser geeinet ist und auf einer seriellen Übertragung der Daten basiert.
%
\section{Elfte Woche}
%
\subsection{Wochenübersicht}
%
Tabelle
%
\subsection{Arbeitsbericht}
%
In der vorliegenden Woche war meine Aufgabe das Perl Programm zu pflegen und ein wenig besser zu strukturieren. Außerdem wurde mir erklärt, dass die Messages, die über die BTE durchgeschaltet, jedoch nicht in die LogListe registriert werden, auch in dem Report vorkommen sollten. Dies geschieht auch bei einem normalen Report, welcher bei einem Test auf dem Computer erzeugt wird. Dies musste ebenfalls im Programm implementiert werden. 

Die aktuelle Version meiner Anwendung erzeugt das auf dem linken Teil gezeigtem File im xml-Format. Das rechts davon gezeigte File ist das Report, welcher wie bereits oben erwähnt bei einem Test auf dem Computer erzeugt wird. Die Unterschiede lassen sich dadurch erklären, dass manche Features, die im auf dem Computer erstellten Report in dem auf der RAM gespeicherten Report nicht relevant sind und somit nicht darzustellen sind. 
%
\begin{landscape}
\begin{figure}[!htp]
\centering
\includegraphics[width=\linewidth,height=150mm]{./Bilder/reports.pdf}
\caption{reports}
\label{fig:reports}
\end{figure}
\end{landscape}
%
Das Bild zum UML Statechart sollte ich mal einfügen und von Markus checken lassen und endgültig hier einfügen.

Am Ende erfogte eine Abgabe der letzten Version meiner programmierten PERL-Anwendung abgegeben werden. Markus hat manche Korrekturen und Verbesserungen durcgeführt und mir dann diesbezüglich Rückmeldung gegeben.
%
\section{Zwolfte Woche}
%
\subsection{Wochenübersicht}
%
Tabelle
%
\subsection{Arbeitsbericht}
%
Diese Woche wurde mir die dritte Aufgabe vorgestellt. Dabei ginge es darum mich mit der Arduino Anwendung und der Einstellung eines geeigneten SCI-Treiber zu beschäftigen. Die Programmierung von Win32-Anwendungen ist nicht trivial, dabei ist man auf die Verwendung von Funktionen angewiesen, die von Windows zur Verfügung gestellt werden. 

Hierbei beschreiben, was Win32 ist und wieso ich nicht andere Module verwenden könnte.

Dabei hat die Programmierung der SCI-Anwendung in VS erfolgt, ich habe mich entschieden das Arduino Projekt nicht wie Andreas vorgeschlagen hat, sondern in AtmelStudio umzusetzen. Die Atmelstudio Anwendung und die Einstellung eines Projektes mit den external configurations beschreiben.

Der programmierte Win32-Treiber arbeitet so, dass die aufzurufende Funktion so lange wartet bis die aufgerufene feritg ist.(waiting rendezvous) nach ~\cite{HardTime}. Die dabei verwendete Methode(...) arbeitet als \grqq timed rendezvous \glqq, wartet also nur eine bestimmte Zeit bis benötigte Task antwortet, ansonsten bricht sie ihren Methodenaufruf ab.